{"cells":[{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-11-09T12:22:40.831011Z","iopub.status.busy":"2023-11-09T12:22:40.830317Z","iopub.status.idle":"2023-11-09T12:22:54.288623Z","shell.execute_reply":"2023-11-09T12:22:54.287558Z","shell.execute_reply.started":"2023-11-09T12:22:40.830975Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Defaulting to user installation because normal site-packages is not writeable\n","Requirement already satisfied: tqdm in /home/akheel/.local/lib/python3.10/site-packages (4.66.1)\n","\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["%pip install tqdm"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-11-09T12:22:54.290986Z","iopub.status.busy":"2023-11-09T12:22:54.290655Z","iopub.status.idle":"2023-11-09T12:23:00.264430Z","shell.execute_reply":"2023-11-09T12:23:00.263612Z","shell.execute_reply.started":"2023-11-09T12:22:54.290953Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import torch\n","\n","from torch.utils.data import DataLoader\n","from torch.optim import SGD\n","from transformers import BertTokenizerFast\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-11-09T12:23:00.266243Z","iopub.status.busy":"2023-11-09T12:23:00.265716Z","iopub.status.idle":"2023-11-09T12:23:00.271138Z","shell.execute_reply":"2023-11-09T12:23:00.270114Z","shell.execute_reply.started":"2023-11-09T12:23:00.266209Z"},"trusted":true},"outputs":[],"source":["NER_DATASETS_DIRECTORY = \"kaggle/input/\"\n","STANDARD_NER_DIRECTORY = \"standard_ner_dataset/\"\n","\n","# INDIAN_LEGAL_NER_DIRECTORY = \"Indian_Legal_NER_Dataset/\"\n","\n","# NER_DATASETS_DIRECTORY = \"All_Data/NER_Datasets/\"\n","# STANDARD_NER_DIRECTORY = \"Standard_NER_Dataset/\"\n","# INDIAN_LEGAL_NER_DIRECTORY = \"Indian_Legal_NER_Dataset/\""]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-11-09T12:23:00.274487Z","iopub.status.busy":"2023-11-09T12:23:00.273849Z","iopub.status.idle":"2023-11-09T12:23:00.282039Z","shell.execute_reply":"2023-11-09T12:23:00.281160Z","shell.execute_reply.started":"2023-11-09T12:23:00.274455Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/media/akheel/Windows-SSD/Users/akhee/Documents/Projects/NITK/Major Project/LegalDoc-Retrieval-n-Summarization\n","/media/akheel/Windows-SSD/Users/akhee/Documents/Projects/NITK/Major Project/LegalDoc-Retrieval-n-Summarization\n"]}],"source":["!pwd\n","%cd /media/akheel/Windows-SSD/Users/akhee/Documents/Projects/NITK/Major Project/LegalDoc-Retrieval-n-Summarization/"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-11-09T12:23:00.283463Z","iopub.status.busy":"2023-11-09T12:23:00.283122Z","iopub.status.idle":"2023-11-09T12:23:00.496671Z","shell.execute_reply":"2023-11-09T12:23:00.495746Z","shell.execute_reply.started":"2023-11-09T12:23:00.283432Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["df.shape: (47959, 2)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Thousands of demonstrators have marched throug...</td>\n","      <td>O O O O O O B-geo O O O O O B-geo O O O O O B-...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Iranian officials say they expect to get acces...</td>\n","      <td>B-gpe O O O O O O O O O O O O O O B-tim O O O ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Helicopter gunships Saturday pounded militant ...</td>\n","      <td>O O B-tim O O O O O B-geo O O O O O B-org O O ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>They left after a tense hour-long standoff wit...</td>\n","      <td>O O O O O O O O O O O</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>U.N. relief coordinator Jan Egeland said Sunda...</td>\n","      <td>B-geo O O B-per I-per O B-tim O B-geo O B-gpe ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                text  \\\n","0  Thousands of demonstrators have marched throug...   \n","1  Iranian officials say they expect to get acces...   \n","2  Helicopter gunships Saturday pounded militant ...   \n","3  They left after a tense hour-long standoff wit...   \n","4  U.N. relief coordinator Jan Egeland said Sunda...   \n","\n","                                              labels  \n","0  O O O O O O B-geo O O O O O B-geo O O O O O B-...  \n","1  B-gpe O O O O O O O O O O O O O O B-tim O O O ...  \n","2  O O B-tim O O O O O B-geo O O O O O B-org O O ...  \n","3                              O O O O O O O O O O O  \n","4  B-geo O O B-per I-per O B-tim O B-geo O B-gpe ...  "]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["# df = pd.read_csv('/kaggle/input/standard-ner-dataset/standard_NER.csv')\n","df = pd.read_csv('All_Data/NER_Datasets/Standard_NER_Dataset/standard_NER.csv')\n","print(f\"df.shape: {df.shape}\")\n","df.head()"]},{"cell_type":"markdown","metadata":{},"source":["**There exists 9 entity categories:**\n","- geo for geographical entity\n","- org for organization entity\n","- per for person entity\n","- gpe for geopolitical entity\n","- tim for time indicator entity\n","- art for artifact entity\n","- eve for event entity\n","- nat for natural phenomenon entity\n","- O is assigned if a word doesn’t belong to any entity.\n","\n","**Each except O has a beginning and Intermediate tag as well. Bringing the total to 17 categories of tagging**"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-11-09T12:23:00.498193Z","iopub.status.busy":"2023-11-09T12:23:00.497899Z","iopub.status.idle":"2023-11-09T12:23:00.634305Z","shell.execute_reply":"2023-11-09T12:23:00.633446Z","shell.execute_reply.started":"2023-11-09T12:23:00.498167Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["{'I-org', 'I-eve', 'B-nat', 'I-gpe', 'I-art', 'I-tim', 'O', 'B-gpe', 'B-art', 'B-per', 'B-org', 'I-per', 'B-tim', 'I-nat', 'B-geo', 'I-geo', 'B-eve'}\n","{'B-art': 0, 'B-eve': 1, 'B-geo': 2, 'B-gpe': 3, 'B-nat': 4, 'B-org': 5, 'B-per': 6, 'B-tim': 7, 'I-art': 8, 'I-eve': 9, 'I-geo': 10, 'I-gpe': 11, 'I-nat': 12, 'I-org': 13, 'I-per': 14, 'I-tim': 15, 'O': 16}\n"]}],"source":["# Split labels based on whitespace and turn them into a list\n","labels = [i.split() for i in df['labels'].values.tolist()]\n","\n","# Check how many labels are there in the dataset\n","unique_labels = set()\n","\n","for lb in labels:\n","  [unique_labels.add(i) for i in lb if i not in unique_labels]\n"," \n","print(unique_labels)\n","\n","# Map each label into its id representation and vice versa\n","labels_to_ids = {k: v for v, k in enumerate(sorted(unique_labels))}\n","ids_to_labels = {v: k for v, k in enumerate(sorted(unique_labels))}\n","\n","print(labels_to_ids)"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-11-09T12:23:00.636355Z","iopub.status.busy":"2023-11-09T12:23:00.635989Z","iopub.status.idle":"2023-11-09T12:23:00.641200Z","shell.execute_reply":"2023-11-09T12:23:00.640211Z","shell.execute_reply.started":"2023-11-09T12:23:00.636323Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["17\n"]}],"source":["num_labels = len(labels_to_ids)\n","print(num_labels)"]},{"cell_type":"markdown","metadata":{},"source":["**We define a DataSequence Class**\n","- This class, when initialized, will split the labels and all texts into their own lists.\n","- It contains texts that is essentially each text, tokenized, with 512 max_length\n","- Labels are made from each label list, but are corrected for the subword tokenizing BERT performs, as well as padding\n","    - If a word does not have an idx, its label id is -100\n","    - If a word is part of / following a previous word / is essentially a subword token, it is given the same id as previous.\n","    - If a word is new, it is given the same id it currently has"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-11-09T12:23:00.642724Z","iopub.status.busy":"2023-11-09T12:23:00.642435Z","iopub.status.idle":"2023-11-09T12:23:01.510840Z","shell.execute_reply":"2023-11-09T12:23:01.510022Z","shell.execute_reply.started":"2023-11-09T12:23:00.642701Z"},"trusted":true},"outputs":[],"source":["tokenizer = BertTokenizerFast.from_pretrained('bert-base-cased')\n","\n","def align_label(texts, labels):\n","  tokenized_inputs = tokenizer(texts, padding='max_length', max_length=512, truncation=True)\n","  word_ids = tokenized_inputs.word_ids()\n","  previous_word_idx = None\n","  label_ids = []\n","  for word_idx in word_ids:\n","    if word_idx is None:\n","      label_ids.append(-100)\n","    elif word_idx != previous_word_idx:\n","      try:\n","        label_ids.append(labels_to_ids[labels[word_idx]])\n","      except:\n","        label_ids.append(-100)\n","    else:\n","      try:\n","        label_ids.append(labels_to_ids[labels[word_idx]])\n","      except:\n","        label_ids.append(-100)\n","    previous_word_idx = word_idx\n","  return label_ids\n","\n","\n","class DataSequence(torch.utils.data.Dataset):\n","  def __init__(self, df):\n","    lb = [i.split() for i in df['labels'].values.tolist()]\n","    txt = df['text'].values.tolist()\n","    self.texts = [tokenizer(str(i), padding='max_length', max_length = 512, truncation=True, return_tensors=\"pt\") for i in txt]\n","    self.labels = [align_label(i,j) for i,j in zip(txt, lb)]\n","\n","  def __len__(self):\n","    return len(self.labels)\n","  \n","  def get_batch_data(self, idx):\n","    return self.texts[idx]\n","  \n","  def get_batch_labels(self, idx):\n","    return torch.LongTensor(self.labels[idx])\n","  \n","  def __getitem__(self, idx):\n","    batch_data = self.get_batch_data(idx)\n","    batch_labels = self.get_batch_labels(idx)\n","    return batch_data, batch_labels"]},{"cell_type":"markdown","metadata":{},"source":["**With the DataSequence Class Defined, We can split the actual Data**  \n","For building model we just use 1000"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-11-09T12:23:01.512072Z","iopub.status.busy":"2023-11-09T12:23:01.511820Z","iopub.status.idle":"2023-11-09T12:23:01.522110Z","shell.execute_reply":"2023-11-09T12:23:01.521240Z","shell.execute_reply.started":"2023-11-09T12:23:01.512051Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/akheel/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n","  return bound(*args, **kwds)\n"]}],"source":["df = df[0:1000]\n","df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=42), [int(.8 * len(df)), int(.9 * len(df))])\n","# print(f\"df_train.shape: {df_train.shape}\")\n","# print(f\"df_val.shape: {df_val.shape}\")\n","# print(f\"df_test.shape: {df_test.shape}\")"]},{"cell_type":"markdown","metadata":{},"source":["## Model Building"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-11-09T12:23:01.526963Z","iopub.status.busy":"2023-11-09T12:23:01.526616Z","iopub.status.idle":"2023-11-09T12:23:09.917607Z","shell.execute_reply":"2023-11-09T12:23:09.916821Z","shell.execute_reply.started":"2023-11-09T12:23:01.526937Z"},"trusted":true},"outputs":[],"source":["from transformers import BertForTokenClassification\n","\n","class BertModel(torch.nn.Module):\n","\n","  def __init__(self):\n","    super(BertModel, self).__init__()\n","    self.bert = BertForTokenClassification.from_pretrained('bert-base-cased', num_labels=len(unique_labels))\n","  \n","  def forward(self, input_id, mask, label):\n","    output = self.bert(input_ids=input_id, attention_mask=mask, labels=label, return_dict=False)\n","    return output"]},{"cell_type":"markdown","metadata":{},"source":["## Model Training"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2023-11-09T12:23:09.918921Z","iopub.status.busy":"2023-11-09T12:23:09.918648Z","iopub.status.idle":"2023-11-09T12:23:09.923232Z","shell.execute_reply":"2023-11-09T12:23:09.922199Z","shell.execute_reply.started":"2023-11-09T12:23:09.918898Z"},"trusted":true},"outputs":[],"source":["import os\n","\n","# To prevent parallelization warnings set true for parallelizing or false for not\n","os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\""]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2023-11-09T12:23:09.925127Z","iopub.status.busy":"2023-11-09T12:23:09.924843Z","iopub.status.idle":"2023-11-09T12:24:28.976619Z","shell.execute_reply":"2023-11-09T12:24:28.975018Z","shell.execute_reply.started":"2023-11-09T12:23:09.925103Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"," 13%|█▎        | 21/160 [03:13<21:18,  9.20s/it]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m/media/akheel/Windows-SSD/Users/akhee/Documents/Projects/NITK/Major Project/LegalDoc-Retrieval-n-Summarization/SKW_Enhancement/NER_Scripts/Batchwise_NER_with_bert.ipynb Cell 17\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/akheel/Windows-SSD/Users/akhee/Documents/Projects/NITK/Major%20Project/LegalDoc-Retrieval-n-Summarization/SKW_Enhancement/NER_Scripts/Batchwise_NER_with_bert.ipynb#X22sZmlsZQ%3D%3D?line=83'>84</a>\u001b[0m BATCH_SIZE \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/akheel/Windows-SSD/Users/akhee/Documents/Projects/NITK/Major%20Project/LegalDoc-Retrieval-n-Summarization/SKW_Enhancement/NER_Scripts/Batchwise_NER_with_bert.ipynb#X22sZmlsZQ%3D%3D?line=85'>86</a>\u001b[0m model \u001b[39m=\u001b[39m BertModel()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/media/akheel/Windows-SSD/Users/akhee/Documents/Projects/NITK/Major%20Project/LegalDoc-Retrieval-n-Summarization/SKW_Enhancement/NER_Scripts/Batchwise_NER_with_bert.ipynb#X22sZmlsZQ%3D%3D?line=86'>87</a>\u001b[0m train_loop(model, df_train, df_val)\n","\u001b[1;32m/media/akheel/Windows-SSD/Users/akhee/Documents/Projects/NITK/Major Project/LegalDoc-Retrieval-n-Summarization/SKW_Enhancement/NER_Scripts/Batchwise_NER_with_bert.ipynb Cell 17\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/akheel/Windows-SSD/Users/akhee/Documents/Projects/NITK/Major%20Project/LegalDoc-Retrieval-n-Summarization/SKW_Enhancement/NER_Scripts/Batchwise_NER_with_bert.ipynb#X22sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m input_id \u001b[39m=\u001b[39m train_data[\u001b[39m'\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39msqueeze(\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/akheel/Windows-SSD/Users/akhee/Documents/Projects/NITK/Major%20Project/LegalDoc-Retrieval-n-Summarization/SKW_Enhancement/NER_Scripts/Batchwise_NER_with_bert.ipynb#X22sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/media/akheel/Windows-SSD/Users/akhee/Documents/Projects/NITK/Major%20Project/LegalDoc-Retrieval-n-Summarization/SKW_Enhancement/NER_Scripts/Batchwise_NER_with_bert.ipynb#X22sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m loss, logits \u001b[39m=\u001b[39m model(input_id, mask, train_label)\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/akheel/Windows-SSD/Users/akhee/Documents/Projects/NITK/Major%20Project/LegalDoc-Retrieval-n-Summarization/SKW_Enhancement/NER_Scripts/Batchwise_NER_with_bert.ipynb#X22sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(logits\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]):\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/akheel/Windows-SSD/Users/akhee/Documents/Projects/NITK/Major%20Project/LegalDoc-Retrieval-n-Summarization/SKW_Enhancement/NER_Scripts/Batchwise_NER_with_bert.ipynb#X22sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m   logits_clean \u001b[39m=\u001b[39m logits[i][train_label[i] \u001b[39m!=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m100\u001b[39m]\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n","\u001b[1;32m/media/akheel/Windows-SSD/Users/akhee/Documents/Projects/NITK/Major Project/LegalDoc-Retrieval-n-Summarization/SKW_Enhancement/NER_Scripts/Batchwise_NER_with_bert.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/akheel/Windows-SSD/Users/akhee/Documents/Projects/NITK/Major%20Project/LegalDoc-Retrieval-n-Summarization/SKW_Enhancement/NER_Scripts/Batchwise_NER_with_bert.ipynb#X22sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, input_id, mask, label):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/media/akheel/Windows-SSD/Users/akhee/Documents/Projects/NITK/Major%20Project/LegalDoc-Retrieval-n-Summarization/SKW_Enhancement/NER_Scripts/Batchwise_NER_with_bert.ipynb#X22sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m   output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbert(input_ids\u001b[39m=\u001b[39;49minput_id, attention_mask\u001b[39m=\u001b[39;49mmask, labels\u001b[39m=\u001b[39;49mlabel, return_dict\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/akheel/Windows-SSD/Users/akhee/Documents/Projects/NITK/Major%20Project/LegalDoc-Retrieval-n-Summarization/SKW_Enhancement/NER_Scripts/Batchwise_NER_with_bert.ipynb#X22sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m output\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:1758\u001b[0m, in \u001b[0;36mBertForTokenClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1752\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1754\u001b[0m \u001b[39m    Labels for computing the token classification loss. Indices should be in `[0, ..., config.num_labels - 1]`.\u001b[39;00m\n\u001b[1;32m   1755\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1756\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1758\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbert(\n\u001b[1;32m   1759\u001b[0m     input_ids,\n\u001b[1;32m   1760\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1761\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[1;32m   1762\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m   1763\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1764\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1765\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1766\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1767\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1768\u001b[0m )\n\u001b[1;32m   1770\u001b[0m sequence_output \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1772\u001b[0m sequence_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(sequence_output)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:1022\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1013\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m   1015\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[1;32m   1016\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[1;32m   1017\u001b[0m     position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     past_key_values_length\u001b[39m=\u001b[39mpast_key_values_length,\n\u001b[1;32m   1021\u001b[0m )\n\u001b[0;32m-> 1022\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m   1023\u001b[0m     embedding_output,\n\u001b[1;32m   1024\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m   1025\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1026\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m   1027\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[1;32m   1028\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   1029\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1030\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1031\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1032\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1033\u001b[0m )\n\u001b[1;32m   1034\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1035\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:612\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    603\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[1;32m    604\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    605\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    609\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    610\u001b[0m     )\n\u001b[1;32m    611\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 612\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m    613\u001b[0m         hidden_states,\n\u001b[1;32m    614\u001b[0m         attention_mask,\n\u001b[1;32m    615\u001b[0m         layer_head_mask,\n\u001b[1;32m    616\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    617\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    618\u001b[0m         past_key_value,\n\u001b[1;32m    619\u001b[0m         output_attentions,\n\u001b[1;32m    620\u001b[0m     )\n\u001b[1;32m    622\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    623\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:497\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    486\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    487\u001b[0m     hidden_states: torch\u001b[39m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    494\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor]:\n\u001b[1;32m    495\u001b[0m     \u001b[39m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    496\u001b[0m     self_attn_past_key_value \u001b[39m=\u001b[39m past_key_value[:\u001b[39m2\u001b[39m] \u001b[39mif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 497\u001b[0m     self_attention_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[1;32m    498\u001b[0m         hidden_states,\n\u001b[1;32m    499\u001b[0m         attention_mask,\n\u001b[1;32m    500\u001b[0m         head_mask,\n\u001b[1;32m    501\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    502\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mself_attn_past_key_value,\n\u001b[1;32m    503\u001b[0m     )\n\u001b[1;32m    504\u001b[0m     attention_output \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    506\u001b[0m     \u001b[39m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:427\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    418\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    419\u001b[0m     hidden_states: torch\u001b[39m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    425\u001b[0m     output_attentions: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    426\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor]:\n\u001b[0;32m--> 427\u001b[0m     self_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself(\n\u001b[1;32m    428\u001b[0m         hidden_states,\n\u001b[1;32m    429\u001b[0m         attention_mask,\n\u001b[1;32m    430\u001b[0m         head_mask,\n\u001b[1;32m    431\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    432\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    433\u001b[0m         past_key_value,\n\u001b[1;32m    434\u001b[0m         output_attentions,\n\u001b[1;32m    435\u001b[0m     )\n\u001b[1;32m    436\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput(self_outputs[\u001b[39m0\u001b[39m], hidden_states)\n\u001b[1;32m    437\u001b[0m     outputs \u001b[39m=\u001b[39m (attention_output,) \u001b[39m+\u001b[39m self_outputs[\u001b[39m1\u001b[39m:]  \u001b[39m# add attentions if we output them\u001b[39;00m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:359\u001b[0m, in \u001b[0;36mBertSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    355\u001b[0m attention_probs \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39msoftmax(attention_scores, dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    357\u001b[0m \u001b[39m# This is actually dropping out entire tokens to attend to, which might\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \u001b[39m# seem a bit unusual, but is taken from the original Transformer paper.\u001b[39;00m\n\u001b[0;32m--> 359\u001b[0m attention_probs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout(attention_probs)\n\u001b[1;32m    361\u001b[0m \u001b[39m# Mask heads if we want to\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \u001b[39mif\u001b[39;00m head_mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/dropout.py:58\u001b[0m, in \u001b[0;36mDropout.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m---> 58\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mdropout(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mp, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minplace)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/functional.py:1266\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1264\u001b[0m \u001b[39mif\u001b[39;00m p \u001b[39m<\u001b[39m \u001b[39m0.0\u001b[39m \u001b[39mor\u001b[39;00m p \u001b[39m>\u001b[39m \u001b[39m1.0\u001b[39m:\n\u001b[1;32m   1265\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[39m{\u001b[39;00mp\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1266\u001b[0m \u001b[39mreturn\u001b[39;00m _VF\u001b[39m.\u001b[39mdropout_(\u001b[39minput\u001b[39m, p, training) \u001b[39mif\u001b[39;00m inplace \u001b[39melse\u001b[39;00m _VF\u001b[39m.\u001b[39;49mdropout(\u001b[39minput\u001b[39;49m, p, training)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["def train_loop(model, df_train, df_val):\n","\n","  train_dataset = DataSequence(df_train)\n","  val_dataset = DataSequence(df_val)\n","\n","  train_dataloader = DataLoader(train_dataset, num_workers=4, batch_size=BATCH_SIZE, shuffle=True)\n","  val_dataloader = DataLoader(val_dataset, num_workers=4, batch_size=BATCH_SIZE)\n","\n","  use_cuda = torch.cuda.is_available()\n","  device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","  optimizer = SGD(model.parameters(), lr=LEARNING_RATE)\n","\n","  if use_cuda:\n","    print(\"Im using Cudaa\")\n","    model = model.cuda()\n","\n","  best_acc = 0\n","  best_loss = 1000\n","\n","  for epoch_num in range(EPOCHS):\n","\n","    total_acc_train = 0\n","    total_loss_train = 0\n","\n","    model.train()\n","\n","    for train_data, train_label in tqdm(train_dataloader):\n","\n","      train_label = train_label.to(device)\n","      mask = train_data['attention_mask'].squeeze(1).to(device)\n","      input_id = train_data['input_ids'].squeeze(1).to(device)\n","      \n","      optimizer.zero_grad()\n","      loss, logits = model(input_id, mask, train_label)\n","      \n","      for i in range(logits.shape[0]):\n","        \n","        logits_clean = logits[i][train_label[i] != -100]\n","        label_clean = train_label[i][train_label[i] != -100]\n","\n","        predictions = logits_clean.argmax(dim=1)\n","        acc = (predictions == label_clean).float().mean()\n","        total_acc_train += acc\n","        total_loss_train += loss.item()\n","        \n","      loss.backward()\n","      optimizer.step()\n","\n","    model.eval()\n","\n","    total_acc_val = 0\n","    total_loss_val = 0\n","\n","    for val_data, val_label in val_dataloader:\n","\n","      val_label = val_label.to(device)\n","      mask = val_data['attention_mask'].squeeze(1).to(device)\n","      input_id = val_data['input_ids'].squeeze(1).to(device)\n","\n","      loss, logits = model(input_id, mask, val_label)\n","\n","      for i in range(logits.shape[0]):\n","\n","        logits_clean = logits[i][val_label[i] != -100]\n","        label_clean = val_label[i][val_label[i] != -100]\n","\n","        predictions = logits_clean.argmax(dim=1)\n","        acc = (predictions == label_clean).float().mean()\n","        total_acc_val += acc\n","        total_loss_val += loss.item()\n","\n","    val_accuracy = total_acc_val / len(df_val)\n","    val_loss = total_loss_val / len(df_val)\n","\n","    print(f\"Epochs: {epoch_num + 1} | \"\n","          f\"Loss: {total_loss_train / len(df_train): .3f} | \"\n","          f\"Accuracy: {total_acc_train / len(df_train): .3f} | \"\n","          f\"Val_Loss: {total_loss_val / len(df_val): .3f} | \"\n","          f\"Accuracy: {total_acc_val / len(df_val): .3f}\")\n","\n","LEARNING_RATE = 5e-3\n","EPOCHS = 5\n","BATCH_SIZE = 5\n","\n","model = BertModel()\n","train_loop(model, df_train, df_val)"]},{"cell_type":"markdown","metadata":{},"source":["### Saving Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-11-09T12:24:28.978084Z","iopub.status.idle":"2023-11-09T12:24:28.978608Z","shell.execute_reply":"2023-11-09T12:24:28.978367Z","shell.execute_reply.started":"2023-11-09T12:24:28.978344Z"},"trusted":true},"outputs":[],"source":["# # For tensor flow\n","# # Save the model architecture to a JSON file\n","# model_json = model.to_json()\n","# with open(\"bert_model.json\", \"w\") as json_file:\n","#     json_file.write(model_json)\n","\n","# # Save the model weights to a separate file\n","# model.save_weights(\"bert_model_weights.h5\")\n","\n","# For PyTorch\n","# Save the entire model (including architecture and weights)\n","torch.save(model, \"NER_With_Bert_5Epoch_NotFullData_17Batch.pth\")\n","\n","# model.export('NER_With_Bert_5Epoch_NotFullData.pkl')"]},{"cell_type":"markdown","metadata":{},"source":["### Loading Model Back"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-11-09T12:24:28.980297Z","iopub.status.idle":"2023-11-09T12:24:28.980772Z","shell.execute_reply":"2023-11-09T12:24:28.980564Z","shell.execute_reply.started":"2023-11-09T12:24:28.980541Z"},"trusted":true},"outputs":[],"source":["import torch\n","\n","# Load the entire PyTorch model\n","model = torch.load(\"/kaggle/input/ner-with-bert-models/NER_With_Bert_5Epoch_NotFullData.pth\")\n"]},{"cell_type":"markdown","metadata":{},"source":["## Model Evaluating"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-11-09T12:24:28.982641Z","iopub.status.idle":"2023-11-09T12:24:28.983104Z","shell.execute_reply":"2023-11-09T12:24:28.982888Z","shell.execute_reply.started":"2023-11-09T12:24:28.982866Z"},"trusted":true},"outputs":[],"source":["def evaluate(model, df_test):\n","\n","  test_dataset = DataSequence(df_test)\n","\n","  test_dataloader = DataLoader(test_dataset, num_workers=4, batch_size=1)\n","\n","  use_cuda = torch.cuda.is_available()\n","  device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","  if use_cuda:\n","    model = model.cuda()\n","\n","  total_acc_test = 0.0\n","\n","  for test_data, test_label in test_dataloader:\n","\n","    test_label = test_label.to(device)\n","    mask = test_data['attention_mask'].squeeze(1).to(device)\n","    \n","    input_id = test_data['input_ids'].squeeze(1).to(device)\n","    \n","    loss, logits = model(input_id, mask, test_label)\n","    \n","    for i in range(logits.shape[0]):\n","      \n","      logits_clean = logits[i][test_label[i] != -100]\n","      label_clean = test_label[i][test_label[i] != -100]\n","      \n","      predictions = logits_clean.argmax(dim=1)\n","      acc = (predictions == label_clean).float().mean()\n","      total_acc_test += acc\n","\n","  val_accuracy = total_acc_test / len(df_test)\n","  print(f'Test Accuracy: {total_acc_test / len(df_test): .3f}')\n","\n","\n","evaluate(model, df_test)"]},{"cell_type":"markdown","metadata":{},"source":["## Model Usage Testing"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-11-09T12:24:28.985064Z","iopub.status.idle":"2023-11-09T12:24:28.985437Z","shell.execute_reply":"2023-11-09T12:24:28.985261Z","shell.execute_reply.started":"2023-11-09T12:24:28.985245Z"},"trusted":true},"outputs":[],"source":["def align_word_ids(texts):\n","  \n","  tokenized_inputs = tokenizer(texts, padding='max_length', max_length=512, truncation=True)\n","\n","  word_ids = tokenized_inputs.word_ids()\n","\n","  previous_word_idx = None\n","  label_ids = []\n","\n","  for word_idx in word_ids:\n","\n","    if word_idx is None:\n","      label_ids.append(-100)\n","        \n","    elif word_idx != previous_word_idx:\n","      try:\n","        label_ids.append(1)\n","      except:\n","        label_ids.append(-100)\n","    else:\n","      try:\n","        label_ids.append(1)\n","      except:\n","        label_ids.append(-100)\n","    previous_word_idx = word_idx\n","\n","  return label_ids\n","\n","\n","def evaluate_one_text(model, sentence):\n","\n","  use_cuda = torch.cuda.is_available()\n","  device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","  if use_cuda:\n","    model = model.cuda()\n","\n","  text = tokenizer(sentence, padding='max_length', max_length = 512, truncation=True, return_tensors=\"pt\")\n","\n","  mask = text['attention_mask'].to(device)\n","  input_id = text['input_ids'].to(device)\n","  label_ids = torch.Tensor(align_word_ids(sentence)).unsqueeze(0).to(device)\n","\n","  logits = model(input_id, mask, None)\n","  logits_clean = logits[0][label_ids != -100]\n","\n","  predictions = logits_clean.argmax(dim=1).tolist()\n","  prediction_label = [ids_to_labels[i] for i in predictions]\n","  print(sentence)\n","  print(prediction_label)\n","\n","  return prediction_label\n","            \n","evaluate_one_text(model, 'Bill Gates is the founder of Microsoft')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-11-09T12:24:28.986665Z","iopub.status.idle":"2023-11-09T12:24:28.986995Z","shell.execute_reply":"2023-11-09T12:24:28.986850Z","shell.execute_reply.started":"2023-11-09T12:24:28.986834Z"},"trusted":true},"outputs":[],"source":["SAMPLE_DOCUMENT_SUMMARIES_DIR = '/kaggle/input/sample-document-summaries-for-skw-dataset/'\n","INDIAN_SUMMARY_FILE = '1.txt'\n","UK_SUMMARY_FILE = 'uksc-2009-0019.txt'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-11-09T12:24:28.988227Z","iopub.status.idle":"2023-11-09T12:24:28.988578Z","shell.execute_reply":"2023-11-09T12:24:28.988422Z","shell.execute_reply.started":"2023-11-09T12:24:28.988403Z"},"trusted":true},"outputs":[],"source":["summaryFilePaths = [SAMPLE_DOCUMENT_SUMMARIES_DIR + fileName for fileName in [INDIAN_SUMMARY_FILE, UK_SUMMARY_FILE]]\n","\n","summaries = []\n","for path in summaryFilePaths:\n","    with open(path, 'r', encoding='utf-8') as file:\n","        summary = file.read()\n","        summaries.append(summary)\n","\n","labels = []\n","for summary in summaries:\n","    labels.append(evaluate_one_text(model, summary))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-11-09T12:24:28.989791Z","iopub.status.idle":"2023-11-09T12:24:28.990109Z","shell.execute_reply":"2023-11-09T12:24:28.989959Z","shell.execute_reply.started":"2023-11-09T12:24:28.989945Z"},"trusted":true},"outputs":[],"source":["# summary = summaries[0]\n","# summary_tokens = tokenizer(summary, padding='max_length', max_length=512, truncation=True)\n","# print(summary_tokens[\"input_ids\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-11-09T12:24:28.991261Z","iopub.status.idle":"2023-11-09T12:24:28.991615Z","shell.execute_reply":"2023-11-09T12:24:28.991452Z","shell.execute_reply.started":"2023-11-09T12:24:28.991437Z"},"trusted":true},"outputs":[],"source":["# summary = summaries[1]\n","# summary_tokens = tokenizer(summary, padding='max_length', max_length=512, truncation=True)\n","# print(summary_tokens[\"input_ids\"])\n","# important_ids = [i for i in range(len(label)) if label[i] != 'O']\n","# important_token_ids = [input_id for i, input_id in enumerate(summary_tokens[\"input_ids\"]) if i in set(important_ids)]\n","# print(important_token_ids)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-11-09T12:24:28.993664Z","iopub.status.idle":"2023-11-09T12:24:28.994122Z","shell.execute_reply":"2023-11-09T12:24:28.993899Z","shell.execute_reply.started":"2023-11-09T12:24:28.993878Z"},"trusted":true},"outputs":[],"source":["# print(len(summaries))\n","# print(len(labels))\n","# print(summaries)\n","# print(labels)\n","\n","# for summary, label in zip(summaries, labels):\n","#     summary_tokens = tokenizer(summary, padding='max_length', max_length=512, truncation=True)\n","#     important_ids = [i for i in range(len(label)) if label[i] != 'O']\n","#     important_token_ids = [input_id for i, input_id in enumerate(summary_tokens[\"input_ids\"]) if i in set(important_ids)]\n","# #     important_tokens = [summary_tokens[i] for i in important_ids]\n","#     important_tokens = tokenizer.convert_ids_to_tokens(important_token_ids)\n","#     print(len(summary_tokens))\n","#     print(len(label))\n","#     print(important_tokens)\n","#     print(important_ids)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-11-09T12:24:28.995293Z","iopub.status.idle":"2023-11-09T12:24:28.995755Z","shell.execute_reply":"2023-11-09T12:24:28.995545Z","shell.execute_reply.started":"2023-11-09T12:24:28.995523Z"},"trusted":true},"outputs":[],"source":["# for i, (summary, label) in enumerate(zip(summaries, labels)):\n","#     print(label)\n","#     summary_tokens = tokenizer(summary, padding='max_length', max_length=512, truncation=True)\n","#     important_ids = [i for i in range(len(label)) if label[i] != 'O']\n","#     print(important_ids)\n","#     important_token_ids = [input_id for i, input_id in enumerate(summary_tokens[\"input_ids\"]) if i in set(important_ids)]\n","#     important_tokens = tokenizer.convert_ids_to_tokens(important_token_ids)\n","#     print(f\"{i}: {important_tokens}\")"]},{"cell_type":"markdown","metadata":{},"source":["### Retrieving Non-'O' Words"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-11-09T12:24:28.997732Z","iopub.status.idle":"2023-11-09T12:24:28.998183Z","shell.execute_reply":"2023-11-09T12:24:28.997964Z","shell.execute_reply.started":"2023-11-09T12:24:28.997943Z"},"trusted":true},"outputs":[],"source":["for summary, token_labels in zip(summaries, labels):\n","    # Retrieve non-'O' labeled words and their corresponding tokens\n","    non_o_tokens = []\n","    current_word_tokens = []\n","    \n","    summary_token_ids = tokenizer(summary, padding='max_length', max_length=512, truncation=True)\n","    summary_tokens = tokenizer.convert_ids_to_tokens(summary_token_ids['input_ids'][1:])\n","    \n","    for token, token_id, token_label in zip(summary_tokens, summary_token_ids[\"input_ids\"][1:], token_labels):\n","        print(token, token_id, token_label)\n","        \n","#     print(summary_tokens)\n","#     print(summary_token_ids['input_ids'])\n","#     print(token_labels)\n","\n","    for token_id, label in zip(summary_token_ids['input_ids'][1:], token_labels):\n","        token_text = tokenizer.decode(token_id)\n","\n","        # Handle subword tokens\n","        if token_text.startswith(\"##\"):\n","            if current_word_tokens:\n","                current_word_tokens[-1] += token_text[2:]\n","        else:\n","            if label != 'O':\n","                current_word_tokens.append(token_text)\n","            else:\n","                if current_word_tokens:\n","                    non_o_tokens.append(\" \".join(current_word_tokens))\n","                    current_word_tokens = []\n","\n","    # Check the last word if it's non-'O'\n","    if current_word_tokens:\n","        non_o_tokens.append(\" \".join(current_word_tokens))\n","\n","    # non_o_tokens now contains all non-'O' labeled words, accounting for subword tokens\n","    print(\"Important Words: \", non_o_tokens)"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":3906217,"sourceId":6789890,"sourceType":"datasetVersion"},{"datasetId":3906525,"sourceId":6790618,"sourceType":"datasetVersion"},{"datasetId":3914096,"sourceId":6802628,"sourceType":"datasetVersion"}],"dockerImageVersionId":30559,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
