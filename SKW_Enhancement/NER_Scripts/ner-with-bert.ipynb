{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%pip install tqdm","metadata":{"execution":{"iopub.status.busy":"2023-10-29T16:23:28.091267Z","iopub.execute_input":"2023-10-29T16:23:28.091995Z","iopub.status.idle":"2023-10-29T16:23:39.430665Z","shell.execute_reply.started":"2023-10-29T16:23:28.091960Z","shell.execute_reply":"2023-10-29T16:23:39.429483Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.66.1)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\n\nfrom torch.utils.data import DataLoader\nfrom torch.optim import SGD\nfrom transformers import BertTokenizerFast\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2023-10-29T16:23:39.432836Z","iopub.execute_input":"2023-10-29T16:23:39.433223Z","iopub.status.idle":"2023-10-29T16:23:39.438772Z","shell.execute_reply.started":"2023-10-29T16:23:39.433187Z","shell.execute_reply":"2023-10-29T16:23:39.437779Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"NER_DATASETS_DIRECTORY = \"kaggle/input/\"\nSTANDARD_NER_DIRECTORY = \"standard_ner_dataset/\"\n\n# INDIAN_LEGAL_NER_DIRECTORY = \"Indian_Legal_NER_Dataset/\"\n\n# NER_DATASETS_DIRECTORY = \"All_Data/NER_Datasets/\"\n# STANDARD_NER_DIRECTORY = \"Standard_NER_Dataset/\"\n# INDIAN_LEGAL_NER_DIRECTORY = \"Indian_Legal_NER_Dataset/\"","metadata":{"execution":{"iopub.status.busy":"2023-10-29T16:23:39.439994Z","iopub.execute_input":"2023-10-29T16:23:39.440329Z","iopub.status.idle":"2023-10-29T16:23:39.449195Z","shell.execute_reply.started":"2023-10-29T16:23:39.440295Z","shell.execute_reply":"2023-10-29T16:23:39.448326Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# !pwd\n# %cd /media/akheel/Windows-SSD/Users/akhee/Documents/Projects/NITK/Major Project/LegalDoc-Retrieval-n-Summarization/","metadata":{"execution":{"iopub.status.busy":"2023-10-29T16:23:39.451897Z","iopub.execute_input":"2023-10-29T16:23:39.452214Z","iopub.status.idle":"2023-10-29T16:23:39.457953Z","shell.execute_reply.started":"2023-10-29T16:23:39.452182Z","shell.execute_reply":"2023-10-29T16:23:39.456955Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/standard-ner-dataset/standard_NER.csv')\n# df = pd.read_csv('All_Data/NER_Datasets/Standard_NER_Dataset/standard_NER.csv')\nprint(f\"df.shape: {df.shape}\")\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-29T16:23:39.459142Z","iopub.execute_input":"2023-10-29T16:23:39.459544Z","iopub.status.idle":"2023-10-29T16:23:39.604159Z","shell.execute_reply.started":"2023-10-29T16:23:39.459510Z","shell.execute_reply":"2023-10-29T16:23:39.603251Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"df.shape: (47959, 2)\n","output_type":"stream"},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"                                                text  \\\n0  Thousands of demonstrators have marched throug...   \n1  Iranian officials say they expect to get acces...   \n2  Helicopter gunships Saturday pounded militant ...   \n3  They left after a tense hour-long standoff wit...   \n4  U.N. relief coordinator Jan Egeland said Sunda...   \n\n                                              labels  \n0  O O O O O O B-geo O O O O O B-geo O O O O O B-...  \n1  B-gpe O O O O O O O O O O O O O O B-tim O O O ...  \n2  O O B-tim O O O O O B-geo O O O O O B-org O O ...  \n3                              O O O O O O O O O O O  \n4  B-geo O O B-per I-per O B-tim O B-geo O B-gpe ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Thousands of demonstrators have marched throug...</td>\n      <td>O O O O O O B-geo O O O O O B-geo O O O O O B-...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Iranian officials say they expect to get acces...</td>\n      <td>B-gpe O O O O O O O O O O O O O O B-tim O O O ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Helicopter gunships Saturday pounded militant ...</td>\n      <td>O O B-tim O O O O O B-geo O O O O O B-org O O ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>They left after a tense hour-long standoff wit...</td>\n      <td>O O O O O O O O O O O</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>U.N. relief coordinator Jan Egeland said Sunda...</td>\n      <td>B-geo O O B-per I-per O B-tim O B-geo O B-gpe ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"**There exists 9 entity categories:**\n- geo for geographical entity\n- org for organization entity\n- per for person entity\n- gpe for geopolitical entity\n- tim for time indicator entity\n- art for artifact entity\n- eve for event entity\n- nat for natural phenomenon entity\n- O is assigned if a word doesnâ€™t belong to any entity.\n\n**Each except O has a beginning and Intermediate tag as well. Bringing the total to 17 categories of tagging**","metadata":{}},{"cell_type":"code","source":"# Split labels based on whitespace and turn them into a list\nlabels = [i.split() for i in df['labels'].values.tolist()]\n\n# Check how many labels are there in the dataset\nunique_labels = set()\n\nfor lb in labels:\n  [unique_labels.add(i) for i in lb if i not in unique_labels]\n \nprint(unique_labels)\n\n# Map each label into its id representation and vice versa\nlabels_to_ids = {k: v for v, k in enumerate(sorted(unique_labels))}\nids_to_labels = {v: k for v, k in enumerate(sorted(unique_labels))}\n\nprint(labels_to_ids)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T16:23:39.605574Z","iopub.execute_input":"2023-10-29T16:23:39.606266Z","iopub.status.idle":"2023-10-29T16:23:39.739142Z","shell.execute_reply.started":"2023-10-29T16:23:39.606228Z","shell.execute_reply":"2023-10-29T16:23:39.738097Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"{'B-gpe', 'B-eve', 'I-eve', 'B-tim', 'O', 'I-geo', 'I-gpe', 'I-art', 'B-org', 'I-tim', 'B-art', 'I-org', 'B-geo', 'I-per', 'B-per', 'I-nat', 'B-nat'}\n{'B-art': 0, 'B-eve': 1, 'B-geo': 2, 'B-gpe': 3, 'B-nat': 4, 'B-org': 5, 'B-per': 6, 'B-tim': 7, 'I-art': 8, 'I-eve': 9, 'I-geo': 10, 'I-gpe': 11, 'I-nat': 12, 'I-org': 13, 'I-per': 14, 'I-tim': 15, 'O': 16}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**We define a DataSequence Class**\n- This class, when initialized, will split the labels and all texts into their own lists.\n- It contains texts that is essentially each text, tokenized, with 512 max_length\n- Labels are made from each label list, but are corrected for the subword tokenizing BERT performs, as well as padding\n    - If a word does not have an idx, its label id is -100\n    - If a word is part of / following a previous word / is essentially a subword token, it is given the same id as previous.\n    - If a word is new, it is given the same id it currently has","metadata":{}},{"cell_type":"code","source":"tokenizer = BertTokenizerFast.from_pretrained('bert-base-cased')\n\ndef align_label(texts, labels):\n  tokenized_inputs = tokenizer(texts, padding='max_length', max_length=512, truncation=True)\n  word_ids = tokenized_inputs.word_ids()\n  previous_word_idx = None\n  label_ids = []\n  for word_idx in word_ids:\n    if word_idx is None:\n      label_ids.append(-100)\n    elif word_idx != previous_word_idx:\n      try:\n        label_ids.append(labels_to_ids[labels[word_idx]])\n      except:\n        label_ids.append(-100)\n    else:\n      try:\n        label_ids.append(labels_to_ids[labels[word_idx]])\n      except:\n        label_ids.append(-100)\n    previous_word_idx = word_idx\n  return label_ids\n\n\nclass DataSequence(torch.utils.data.Dataset):\n  def __init__(self, df):\n    lb = [i.split() for i in df['labels'].values.tolist()]\n    txt = df['text'].values.tolist()\n    self.texts = [tokenizer(str(i), padding='max_length', max_length = 512, truncation=True, return_tensors=\"pt\") for i in txt]\n    self.labels = [align_label(i,j) for i,j in zip(txt, lb)]\n\n  def __len__(self):\n    return len(self.labels)\n  \n  def get_batch_data(self, idx):\n    return self.texts[idx]\n  \n  def get_batch_labels(self, idx):\n    return torch.LongTensor(self.labels[idx])\n  \n  def __getitem__(self, idx):\n    batch_data = self.get_batch_data(idx)\n    batch_labels = self.get_batch_labels(idx)\n    return batch_data, batch_labels","metadata":{"execution":{"iopub.status.busy":"2023-10-29T16:23:39.740262Z","iopub.execute_input":"2023-10-29T16:23:39.740575Z","iopub.status.idle":"2023-10-29T16:23:39.886492Z","shell.execute_reply.started":"2023-10-29T16:23:39.740546Z","shell.execute_reply":"2023-10-29T16:23:39.885721Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"**With the DataSequence Class Defined, We can split the actual Data**  \nFor building model we just use 1000","metadata":{}},{"cell_type":"code","source":"df = df[0:1000]\ndf_train, df_val, df_test = np.split(df.sample(frac=1, random_state=42), [int(.8 * len(df)), int(.9 * len(df))])\n# print(f\"df_train.shape: {df_train.shape}\")\n# print(f\"df_val.shape: {df_val.shape}\")\n# print(f\"df_test.shape: {df_test.shape}\")","metadata":{"execution":{"iopub.status.busy":"2023-10-29T16:23:39.887541Z","iopub.execute_input":"2023-10-29T16:23:39.887801Z","iopub.status.idle":"2023-10-29T16:23:39.895523Z","shell.execute_reply.started":"2023-10-29T16:23:39.887777Z","shell.execute_reply":"2023-10-29T16:23:39.894626Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"## Model Building","metadata":{}},{"cell_type":"code","source":"from transformers import BertForTokenClassification\n\nclass BertModel(torch.nn.Module):\n\n  def __init__(self):\n    super(BertModel, self).__init__()\n    self.bert = BertForTokenClassification.from_pretrained('bert-base-cased', num_labels=len(unique_labels))\n  \n  def forward(self, input_id, mask, label):\n    output = self.bert(input_ids=input_id, attention_mask=mask, labels=label, return_dict=False)\n    return output","metadata":{"execution":{"iopub.status.busy":"2023-10-29T16:23:39.896794Z","iopub.execute_input":"2023-10-29T16:23:39.897087Z","iopub.status.idle":"2023-10-29T16:23:39.906848Z","shell.execute_reply.started":"2023-10-29T16:23:39.897061Z","shell.execute_reply":"2023-10-29T16:23:39.906048Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"## Model Training","metadata":{}},{"cell_type":"code","source":"import os\n\n# To prevent parallelization warnings set true for parallelizing or false for not\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"","metadata":{"execution":{"iopub.status.busy":"2023-10-29T16:23:39.910245Z","iopub.execute_input":"2023-10-29T16:23:39.910610Z","iopub.status.idle":"2023-10-29T16:23:39.919798Z","shell.execute_reply.started":"2023-10-29T16:23:39.910584Z","shell.execute_reply":"2023-10-29T16:23:39.919058Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# def train_loop(model, df_train, df_val):\n\n#   train_dataset = DataSequence(df_train)\n#   val_dataset = DataSequence(df_val)\n\n#   train_dataloader = DataLoader(train_dataset, num_workers=4, batch_size=BATCH_SIZE, shuffle=True)\n#   val_dataloader = DataLoader(val_dataset, num_workers=4, batch_size=BATCH_SIZE)\n\n#   use_cuda = torch.cuda.is_available()\n#   device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n\n#   optimizer = SGD(model.parameters(), lr=LEARNING_RATE)\n\n#   if use_cuda:\n#     model = model.cuda()\n\n#   best_acc = 0\n#   best_loss = 1000\n\n#   for epoch_num in range(EPOCHS):\n\n#     total_acc_train = 0\n#     total_loss_train = 0\n\n#     model.train()\n\n#     for train_data, train_label in tqdm(train_dataloader):\n\n#       train_label = train_label.to(device)\n#       mask = train_data['attention_mask'].squeeze(1).to(device)\n#       input_id = train_data['input_ids'].squeeze(1).to(device)\n      \n#       optimizer.zero_grad()\n#       loss, logits = model(input_id, mask, train_label)\n      \n#       for i in range(logits.shape[0]):\n        \n#         logits_clean = logits[i][train_label[i] != -100]\n#         label_clean = train_label[i][train_label[i] != -100]\n\n#         predictions = logits_clean.argmax(dim=1)\n#         acc = (predictions == label_clean).float().mean()\n#         total_acc_train += acc\n#         total_loss_train += loss.item()\n        \n#       loss.backward()\n#       optimizer.step()\n\n#     model.eval()\n\n#     total_acc_val = 0\n#     total_loss_val = 0\n\n#     for val_data, val_label in val_dataloader:\n\n#       val_label = val_label.to(device)\n#       mask = val_data['attention_mask'].squeeze(1).to(device)\n#       input_id = val_data['input_ids'].squeeze(1).to(device)\n\n#       loss, logits = model(input_id, mask, val_label)\n\n#       for i in range(logits.shape[0]):\n\n#         logits_clean = logits[i][val_label[i] != -100]\n#         label_clean = val_label[i][val_label[i] != -100]\n\n#         predictions = logits_clean.argmax(dim=1)\n#         acc = (predictions == label_clean).float().mean()\n#         total_acc_val += acc\n#         total_loss_val += loss.item()\n\n#     val_accuracy = total_acc_val / len(df_val)\n#     val_loss = total_loss_val / len(df_val)\n\n#     print(f\"Epochs: {epoch_num + 1} | \"\n#           f\"Loss: {total_loss_train / len(df_train): .3f} | \"\n#           f\"Accuracy: {total_acc_train / len(df_train): .3f} | \"\n#           f\"Val_Loss: {total_loss_val / len(df_val): .3f} | \"\n#           f\"Accuracy: {total_acc_val / len(df_val): .3f}\")\n\n# LEARNING_RATE = 5e-3\n# EPOCHS = 5\n# BATCH_SIZE = 2\n\n# model = BertModel()\n# train_loop(model, df_train, df_val)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T16:23:39.920713Z","iopub.execute_input":"2023-10-29T16:23:39.920974Z","iopub.status.idle":"2023-10-29T16:23:39.929851Z","shell.execute_reply.started":"2023-10-29T16:23:39.920950Z","shell.execute_reply":"2023-10-29T16:23:39.929064Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"### Saving Model","metadata":{}},{"cell_type":"code","source":"# # # For tensor flow\n# # # Save the model architecture to a JSON file\n# # model_json = model.to_json()\n# # with open(\"bert_model.json\", \"w\") as json_file:\n# #     json_file.write(model_json)\n\n# # # Save the model weights to a separate file\n# # model.save_weights(\"bert_model_weights.h5\")\n\n# # For PyTorch\n# # Save the entire model (including architecture and weights)\n# torch.save(model, \"NER_With_Bert_5Epoch_NotFullData.pth\")\n\n# # model.export('NER_With_Bert_5Epoch_NotFullData.pkl')","metadata":{"execution":{"iopub.status.busy":"2023-10-29T16:23:39.930750Z","iopub.execute_input":"2023-10-29T16:23:39.930983Z","iopub.status.idle":"2023-10-29T16:23:39.942249Z","shell.execute_reply.started":"2023-10-29T16:23:39.930961Z","shell.execute_reply":"2023-10-29T16:23:39.941604Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"### Loading Model Back","metadata":{}},{"cell_type":"code","source":"import torch\n\n# Load the entire PyTorch model\nmodel = torch.load(\"/kaggle/input/ner-with-bert-models/NER_With_Bert_5Epoch_NotFullData.pth\")\n","metadata":{"execution":{"iopub.status.busy":"2023-10-29T16:23:39.943372Z","iopub.execute_input":"2023-10-29T16:23:39.943712Z","iopub.status.idle":"2023-10-29T16:23:40.327391Z","shell.execute_reply.started":"2023-10-29T16:23:39.943687Z","shell.execute_reply":"2023-10-29T16:23:40.326255Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"## Model Evaluating","metadata":{}},{"cell_type":"code","source":"def evaluate(model, df_test):\n\n  test_dataset = DataSequence(df_test)\n\n  test_dataloader = DataLoader(test_dataset, num_workers=4, batch_size=1)\n\n  use_cuda = torch.cuda.is_available()\n  device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n\n  if use_cuda:\n    model = model.cuda()\n\n  total_acc_test = 0.0\n\n  for test_data, test_label in test_dataloader:\n\n    test_label = test_label.to(device)\n    mask = test_data['attention_mask'].squeeze(1).to(device)\n    \n    input_id = test_data['input_ids'].squeeze(1).to(device)\n    \n    loss, logits = model(input_id, mask, test_label)\n    \n    for i in range(logits.shape[0]):\n      \n      logits_clean = logits[i][test_label[i] != -100]\n      label_clean = test_label[i][test_label[i] != -100]\n      \n      predictions = logits_clean.argmax(dim=1)\n      acc = (predictions == label_clean).float().mean()\n      total_acc_test += acc\n\n  val_accuracy = total_acc_test / len(df_test)\n  print(f'Test Accuracy: {total_acc_test / len(df_test): .3f}')\n\n\nevaluate(model, df_test)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T16:23:40.328835Z","iopub.execute_input":"2023-10-29T16:23:40.329152Z","iopub.status.idle":"2023-10-29T16:23:43.006366Z","shell.execute_reply.started":"2023-10-29T16:23:40.329125Z","shell.execute_reply":"2023-10-29T16:23:43.005270Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"Test Accuracy:  0.903\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Model Usage Testing","metadata":{}},{"cell_type":"code","source":"def align_word_ids(texts):\n  \n  tokenized_inputs = tokenizer(texts, padding='max_length', max_length=512, truncation=True)\n\n  word_ids = tokenized_inputs.word_ids()\n\n  previous_word_idx = None\n  label_ids = []\n\n  for word_idx in word_ids:\n\n    if word_idx is None:\n      label_ids.append(-100)\n        \n    elif word_idx != previous_word_idx:\n      try:\n        label_ids.append(1)\n      except:\n        label_ids.append(-100)\n    else:\n      try:\n        label_ids.append(1)\n      except:\n        label_ids.append(-100)\n    previous_word_idx = word_idx\n\n  return label_ids\n\n\ndef evaluate_one_text(model, sentence):\n\n  use_cuda = torch.cuda.is_available()\n  device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n\n  if use_cuda:\n    model = model.cuda()\n\n  text = tokenizer(sentence, padding='max_length', max_length = 512, truncation=True, return_tensors=\"pt\")\n\n  mask = text['attention_mask'].to(device)\n  input_id = text['input_ids'].to(device)\n  label_ids = torch.Tensor(align_word_ids(sentence)).unsqueeze(0).to(device)\n\n  logits = model(input_id, mask, None)\n  logits_clean = logits[0][label_ids != -100]\n\n  predictions = logits_clean.argmax(dim=1).tolist()\n  prediction_label = [ids_to_labels[i] for i in predictions]\n  print(sentence)\n  print(prediction_label)\n\n  return prediction_label\n            \nevaluate_one_text(model, 'Bill Gates is the founder of Microsoft')","metadata":{"execution":{"iopub.status.busy":"2023-10-29T16:23:43.008093Z","iopub.execute_input":"2023-10-29T16:23:43.008404Z","iopub.status.idle":"2023-10-29T16:23:43.053402Z","shell.execute_reply.started":"2023-10-29T16:23:43.008373Z","shell.execute_reply":"2023-10-29T16:23:43.052537Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"Bill Gates is the founder of Microsoft\n['B-per', 'I-per', 'O', 'O', 'O', 'O', 'O']\n","output_type":"stream"},{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"['B-per', 'I-per', 'O', 'O', 'O', 'O', 'O']"},"metadata":{}}]},{"cell_type":"code","source":"SAMPLE_DOCUMENT_SUMMARIES_DIR = '/kaggle/input/sample-document-summaries-for-skw-dataset/'\nINDIAN_SUMMARY_FILE = '1.txt'\nUK_SUMMARY_FILE = 'uksc-2009-0019.txt'","metadata":{"execution":{"iopub.status.busy":"2023-10-29T16:23:43.054510Z","iopub.execute_input":"2023-10-29T16:23:43.054758Z","iopub.status.idle":"2023-10-29T16:23:43.059057Z","shell.execute_reply.started":"2023-10-29T16:23:43.054735Z","shell.execute_reply":"2023-10-29T16:23:43.058113Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"summaryFilePaths = [SAMPLE_DOCUMENT_SUMMARIES_DIR + fileName for fileName in [INDIAN_SUMMARY_FILE, UK_SUMMARY_FILE]]\n\nsummaries = []\nfor path in summaryFilePaths:\n    with open(path, 'r', encoding='utf-8') as file:\n        summary = file.read()\n        summaries.append(summary)\n\nlabels = []\nfor summary in summaries:\n    labels.append(evaluate_one_text(model, summary))","metadata":{"execution":{"iopub.status.busy":"2023-10-29T16:23:43.060365Z","iopub.execute_input":"2023-10-29T16:23:43.060738Z","iopub.status.idle":"2023-10-29T16:23:43.146309Z","shell.execute_reply.started":"2023-10-29T16:23:43.060705Z","shell.execute_reply":"2023-10-29T16:23:43.145448Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"The charge created in respect of municipal property tax by section 212 of the City of Bombay Municipal Act, 1888, is an \"annual charge not being a capital charge\" within the mean ing of section 9 (1) (iv) of the Indian Income tax Act, 199.2, and the amount of such charge should therefore be deducted in computing the income from such property for the purposes of section 9 of the Indian Income tax Act.\nThe charge in respect of urban immoveable property tax created by the Bombay Finance Act, 1939 is similar in character and the amount of such charge should also be deducted.\nThe expression \"capital charge\" in s.9(1) (iv) means a charge created for a capital sum,that is to say, a charge created to. ' secure the discharge of a liability of a capi tal nature; and an \"annual charge\" means a charge to secure an annual liabili ty. 554\n\n['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'B-geo', 'I-org', 'O', 'O', 'B-tim', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-org', 'I-org', 'I-org', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-org', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-org', 'I-org', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\nH is a three year old child whose parents separated before his birth.\nFrom the date of his birth until very recently, H has lived with his maternal grandmother, GB.\nHs mother, GLB, lived with her mother and H intermittently at GBs home from the time he was born until July 2006.\nShe left GBs home then and has not returned.\nIn November 2006, GB was granted, by consent, a residence order in respect of H.\nOn the same occasion orders for contact were made in favour of Hs father, RJB.\nIn May 2008, RJB applied for a residence order in respect of H. By the time the application was heard in the Family Proceedings Court in March 2009, RJB had married and his new wife was expecting their child.\nRJBs application, which was supported by Hs mother, was refused.\nIn making their decision, the justices noted that they had not found compelling reasons to disrupt the continuity of care that GB provided H. RJB appealed the justices decision.\nThat appeal was successful in the High Court, the judge finding that the justices had been plainly wrong in making the residence order in favour of GB, having been distracted by the settled way in which H had been brought up by GB.\nIn April 2009, the High Court made an order that H should reside with RJB.\nThe order of the High Court was appealed by GB in the Court of Appeal.\nThe Court of Appeal dismissed the appeal holding that in giving disproportionate weight to the status quo the justices had made an error of law sufficient to entitle the circuit judge to overrule their decision.\nApplying Re G (Children) (Residence: Same Sex Partner) [2006] 1 WLR 2305, and in particular the observations in that case of Lord Nicholls, the Court of Appeal held that although a childs welfare was the courts paramount consideration, the court should always bear in mind that, ordinarily, the rearing of a child by his biological parent could be expected to be in his best interests.\nThe Supreme Court unanimously allowed the appeal by GB.\nIn doing so, it reaffirmed the central message in Re G that, where in a case between private individuals a childs custody or upbringing is in question, the welfare of the child is the paramount consideration.\nThe judgment delivered by Lord Kerr was the judgment of the court to which all of its members contributed.\nA childs welfare is the paramount consideration in the determination of the question of his or her residence. (Paragraphs [18] [19], [32] [37]) The justices decision was not plainly wrong.\nThey had recognised that Hs welfare was the paramount consideration and had carefully evaluated the evidence before them, correctly weighing up the various competing factors.\nFor this reason, both the judge and the Court of Appeal had erred in overturning the justices decision. (Paragraphs [9] [15], [37] [39]) Both the judge and the Court of Appeal misinterpreted Re G.\nWhen, in that case, Lord Nicholls said that courts should keep in mind that the interests of a child will normally be best served by being reared by his or her biological parent, he was doing no more than reflecting common experience that, in general, children tend to thrive when brought up by parents to whom they have been born.\nAll consideration of the importance of parenthood in private law disputes about residence must be firmly rooted in an examination of what is in the childs best interests.\nThis is the paramount consideration.\nIt is only as a contributor to the childs welfare that parenthood assumes any significance.\nIn common with all other factors bearing on what is in the best interests of the child, it must be examined for its potential to fulfil that aim. (Paragraphs [1], [17], [23] [25], [32] [37]) Any discussion of a childs right to be brought up by its natural parents is misplaced.\nThe only consideration for the court is the childs welfare; to talk of a childs rights detracts from that consideration. (Paragraphs [18] [19]) In this case, there was reason to believe that if Hs bond with GB were broken his current stability would be threatened.\nWhilst RJB was assessed as capable of meeting Hs needs, he had recently undergone significant changes in his own domestic position and his arrangements were untested at the time the justices made their decision.\nIn deciding where Hs best interests lay the justices were therefore right to give significant weight to maintaining the status quo in Hs living arrangements. (Paragraphs [40] [41])\n\n['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-tim', 'I-tim', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-tim', 'I-tim', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-tim', 'I-tim', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-org', 'O', 'O', 'B-tim', 'I-tim', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-tim', 'I-tim', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-org', 'O', 'O', 'O', 'O', 'I-org', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-per', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n","output_type":"stream"}]},{"cell_type":"code","source":"# summary = summaries[0]\n# summary_tokens = tokenizer(summary, padding='max_length', max_length=512, truncation=True)\n# print(summary_tokens[\"input_ids\"])","metadata":{"execution":{"iopub.status.busy":"2023-10-29T16:23:43.147573Z","iopub.execute_input":"2023-10-29T16:23:43.147839Z","iopub.status.idle":"2023-10-29T16:23:43.151698Z","shell.execute_reply.started":"2023-10-29T16:23:43.147815Z","shell.execute_reply":"2023-10-29T16:23:43.150756Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"# summary = summaries[1]\n# summary_tokens = tokenizer(summary, padding='max_length', max_length=512, truncation=True)\n# print(summary_tokens[\"input_ids\"])\n# important_ids = [i for i in range(len(label)) if label[i] != 'O']\n# important_token_ids = [input_id for i, input_id in enumerate(summary_tokens[\"input_ids\"]) if i in set(important_ids)]\n# print(important_token_ids)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T16:23:43.152875Z","iopub.execute_input":"2023-10-29T16:23:43.153512Z","iopub.status.idle":"2023-10-29T16:23:43.163523Z","shell.execute_reply.started":"2023-10-29T16:23:43.153485Z","shell.execute_reply":"2023-10-29T16:23:43.162719Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"# print(len(summaries))\n# print(len(labels))\n# print(summaries)\n# print(labels)\n\n# for summary, label in zip(summaries, labels):\n#     summary_tokens = tokenizer(summary, padding='max_length', max_length=512, truncation=True)\n#     important_ids = [i for i in range(len(label)) if label[i] != 'O']\n#     important_token_ids = [input_id for i, input_id in enumerate(summary_tokens[\"input_ids\"]) if i in set(important_ids)]\n# #     important_tokens = [summary_tokens[i] for i in important_ids]\n#     important_tokens = tokenizer.convert_ids_to_tokens(important_token_ids)\n#     print(len(summary_tokens))\n#     print(len(label))\n#     print(important_tokens)\n#     print(important_ids)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T16:23:43.164440Z","iopub.execute_input":"2023-10-29T16:23:43.164678Z","iopub.status.idle":"2023-10-29T16:23:43.174104Z","shell.execute_reply.started":"2023-10-29T16:23:43.164656Z","shell.execute_reply":"2023-10-29T16:23:43.173318Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"# for i, (summary, label) in enumerate(zip(summaries, labels)):\n#     print(label)\n#     summary_tokens = tokenizer(summary, padding='max_length', max_length=512, truncation=True)\n#     important_ids = [i for i in range(len(label)) if label[i] != 'O']\n#     print(important_ids)\n#     important_token_ids = [input_id for i, input_id in enumerate(summary_tokens[\"input_ids\"]) if i in set(important_ids)]\n#     important_tokens = tokenizer.convert_ids_to_tokens(important_token_ids)\n#     print(f\"{i}: {important_tokens}\")","metadata":{"execution":{"iopub.status.busy":"2023-10-29T16:23:43.175182Z","iopub.execute_input":"2023-10-29T16:23:43.175891Z","iopub.status.idle":"2023-10-29T16:23:43.184030Z","shell.execute_reply.started":"2023-10-29T16:23:43.175857Z","shell.execute_reply":"2023-10-29T16:23:43.183297Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"### Retrieving Non-'O' Words","metadata":{}},{"cell_type":"code","source":"for summary, token_labels in zip(summaries, labels):\n    # Retrieve non-'O' labeled words and their corresponding tokens\n    non_o_tokens = []\n    current_word_tokens = []\n    \n    summary_token_ids = tokenizer(summary, padding='max_length', max_length=512, truncation=True)\n    summary_tokens = tokenizer.convert_ids_to_tokens(summary_token_ids['input_ids'][1:])\n    \n    for token, token_id, token_label in zip(summary_tokens, summary_token_ids[\"input_ids\"][1:], token_labels):\n        print(token, token_id, token_label)\n        \n#     print(summary_tokens)\n#     print(summary_token_ids['input_ids'])\n#     print(token_labels)\n\n    for token_id, label in zip(summary_token_ids['input_ids'][1:], token_labels):\n        token_text = tokenizer.decode(token_id)\n\n        # Handle subword tokens\n        if token_text.startswith(\"##\"):\n            if current_word_tokens:\n                current_word_tokens[-1] += token_text[2:]\n        else:\n            if label != 'O':\n                current_word_tokens.append(token_text)\n            else:\n                if current_word_tokens:\n                    non_o_tokens.append(\" \".join(current_word_tokens))\n                    current_word_tokens = []\n\n    # Check the last word if it's non-'O'\n    if current_word_tokens:\n        non_o_tokens.append(\" \".join(current_word_tokens))\n\n    # non_o_tokens now contains all non-'O' labeled words, accounting for subword tokens\n    print(\"Important Words: \", non_o_tokens)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T16:29:02.814396Z","iopub.execute_input":"2023-10-29T16:29:02.814798Z","iopub.status.idle":"2023-10-29T16:29:02.860219Z","shell.execute_reply.started":"2023-10-29T16:29:02.814763Z","shell.execute_reply":"2023-10-29T16:29:02.859180Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"The 1109 O\ncharge 2965 O\ncreated 1687 O\nin 1107 O\nrespect 4161 O\nof 1104 O\nmunicipal 5186 O\nproperty 2400 O\ntax 3641 O\nby 1118 O\nsection 2237 O\n212 19538 O\nof 1104 O\nthe 1103 O\nCity 1392 B-geo\nof 1104 O\nBombay 11888 B-geo\nMunicipal 7360 I-org\nAct 2173 O\n, 117 O\n1888 6079 B-tim\n, 117 O\nis 1110 O\nan 1126 O\n\" 107 O\nannual 2683 O\ncharge 2965 O\nnot 1136 O\nbeing 1217 O\na 170 O\ncapital 2364 O\ncharge 2965 O\n\" 107 O\nwithin 1439 O\nthe 1103 O\nmean 1928 O\ning 16664 O\nof 1104 O\nsection 2237 O\n9 130 O\n( 113 O\n1 122 O\n) 114 O\n( 113 O\ni 178 O\n##v 1964 O\n) 114 O\nof 1104 O\nthe 1103 O\nIndian 1890 B-org\nInc 3561 I-org\n##ome 6758 I-org\ntax 3641 O\nAct 2173 O\n, 117 O\n199 22690 O\n. 119 O\n2 123 O\n, 117 O\nand 1105 O\nthe 1103 O\namount 2971 O\nof 1104 O\nsuch 1216 O\ncharge 2965 O\nshould 1431 O\ntherefore 3335 O\nbe 1129 O\nde 1260 O\n##ducted 23087 O\nin 1107 O\ncomputing 12783 O\nthe 1103 O\nincome 2467 O\nfrom 1121 O\nsuch 1216 O\nproperty 2400 O\nfor 1111 O\nthe 1103 O\npurposes 4998 O\nof 1104 O\nsection 2237 O\n9 130 O\nof 1104 O\nthe 1103 O\nIndian 1890 B-org\nInc 3561 O\n##ome 6758 O\ntax 3641 O\nAct 2173 O\n. 119 O\nThe 1109 O\ncharge 2965 O\nin 1107 O\nrespect 4161 O\nof 1104 O\nurban 3953 O\nim 13280 O\n##mo 3702 O\n##ve 2707 O\n##able 1895 O\nproperty 2400 O\ntax 3641 O\ncreated 1687 O\nby 1118 O\nthe 1103 O\nBombay 11888 B-org\nFinance 7476 I-org\nAct 2173 O\n, 117 O\n1939 3061 O\nis 1110 O\nsimilar 1861 O\nin 1107 O\ncharacter 1959 O\nand 1105 O\nthe 1103 O\namount 2971 O\nof 1104 O\nsuch 1216 O\ncharge 2965 O\nshould 1431 O\nalso 1145 O\nbe 1129 O\nde 1260 O\n##ducted 23087 O\n. 119 O\nThe 1109 O\nexpression 2838 O\n\" 107 O\ncapital 2364 O\ncharge 2965 O\n\" 107 O\nin 1107 O\ns 188 O\n. 119 O\n9 130 O\n( 113 O\n1 122 O\n) 114 O\n( 113 O\ni 178 O\n##v 1964 O\n) 114 O\nmeans 2086 O\na 170 O\ncharge 2965 O\ncreated 1687 O\nfor 1111 O\na 170 O\ncapital 2364 O\nsum 7584 O\n, 117 O\nthat 1115 O\nis 1110 O\nto 1106 O\nsay 1474 O\n, 117 O\na 170 O\ncharge 2965 O\ncreated 1687 O\nto 1106 O\n. 119 O\n' 112 O\nsecure 5343 O\nthe 1103 O\ndischarge 12398 O\nof 1104 O\na 170 O\nliability 15509 O\nof 1104 O\na 170 O\ncap 6707 O\n##i 1182 O\nta 27629 O\n##l 1233 O\nnature 2731 O\n; 132 O\nand 1105 O\nan 1126 O\n\" 107 O\nannual 2683 O\ncharge 2965 O\n\" 107 O\nmeans 2086 O\na 170 O\ncharge 2965 O\nto 1106 O\nsecure 5343 O\nan 1126 O\nannual 2683 O\nl 181 O\n##ia 1465 O\n##bil 15197 O\n##i 1182 O\nt 189 O\n##y 1183 O\n. 119 O\n55 3731 O\n##4 1527 O\nImportant Words:  ['City', 'Bombay Municipal', '1888', 'Indian Income', 'Indian', 'Bombay Finance']\nH 145 O\nis 1110 O\na 170 O\nthree 1210 O\nyear 1214 O\nold 1385 O\nchild 2027 O\nwhose 2133 O\nparents 2153 O\nseparated 4757 O\nbefore 1196 O\nhis 1117 O\nbirth 3485 O\n. 119 O\nFrom 1622 O\nthe 1103 O\ndate 2236 O\nof 1104 O\nhis 1117 O\nbirth 3485 O\nuntil 1235 O\nvery 1304 O\nrecently 3055 O\n, 117 O\nH 145 O\nhas 1144 O\nlived 2077 O\nwith 1114 O\nhis 1117 O\nmaternal 11476 O\ngrandmother 6907 O\n, 117 O\nGB 17909 O\n. 119 O\nH 145 O\n##s 1116 O\nmother 1534 O\n, 117 O\nG 144 O\n##L 2162 O\n##B 2064 O\n, 117 O\nlived 2077 O\nwith 1114 O\nher 1123 O\nmother 1534 O\nand 1105 O\nH 145 O\nintermittent 27946 O\n##ly 1193 O\nat 1120 O\nGB 17909 O\n##s 1116 O\nhome 1313 O\nfrom 1121 O\nthe 1103 O\ntime 1159 O\nhe 1119 O\nwas 1108 O\nborn 1255 O\nuntil 1235 O\nJuly 1351 B-tim\n2006 1386 I-tim\n. 119 O\nShe 1153 O\nleft 1286 O\nGB 17909 O\n##s 1116 O\nhome 1313 O\nthen 1173 O\nand 1105 O\nhas 1144 O\nnot 1136 O\nreturned 1608 O\n. 119 O\nIn 1130 O\nNovember 1379 B-tim\n2006 1386 I-tim\n, 117 O\nGB 17909 O\nwas 1108 O\ngranted 3609 O\n, 117 O\nby 1118 O\nconsent 9635 O\n, 117 O\na 170 O\nresidence 4662 O\norder 1546 O\nin 1107 O\nrespect 4161 O\nof 1104 O\nH 145 O\n. 119 O\nOn 1212 O\nthe 1103 O\nsame 1269 O\noccasion 6116 O\norders 3791 O\nfor 1111 O\ncontact 3232 O\nwere 1127 O\nmade 1189 O\nin 1107 O\nfavour 7511 O\nof 1104 O\nH 145 O\n##s 1116 O\nfather 1401 O\n, 117 O\nR 155 O\n##J 4538 O\n##B 2064 O\n. 119 O\nIn 1130 O\nMay 1318 B-tim\n2008 1369 I-tim\n, 117 O\nR 155 O\n##J 4538 O\n##B 2064 O\napplied 3666 O\nfor 1111 O\na 170 O\nresidence 4662 O\norder 1546 O\nin 1107 O\nrespect 4161 O\nof 1104 O\nH 145 O\n. 119 O\nBy 1650 O\nthe 1103 O\ntime 1159 O\nthe 1103 O\napplication 4048 O\nwas 1108 O\nheard 1767 O\nin 1107 O\nthe 1103 O\nFamily 3921 O\nProceedings 20661 I-org\nCourt 2031 O\nin 1107 O\nMarch 1345 B-tim\n2009 1371 I-tim\n, 117 O\nR 155 O\n##J 4538 O\n##B 2064 O\nhad 1125 O\nmarried 1597 O\nand 1105 O\nhis 1117 O\nnew 1207 O\nwife 1676 O\nwas 1108 O\nexpecting 7805 O\ntheir 1147 O\nchild 2027 O\n. 119 O\nR 155 O\n##J 4538 O\n##B 2064 O\n##s 1116 O\napplication 4048 O\n, 117 O\nwhich 1134 O\nwas 1108 O\nsupported 2726 O\nby 1118 O\nH 145 O\n##s 1116 O\nmother 1534 O\n, 117 O\nwas 1108 O\nrefused 3347 O\n. 119 O\nIn 1130 O\nmaking 1543 O\ntheir 1147 O\ndecision 2383 O\n, 117 O\nthe 1103 O\njustice 5299 O\n##s 1116 O\nnoted 2382 O\nthat 1115 O\nthey 1152 O\nhad 1125 O\nnot 1136 O\nfound 1276 O\ncompelling 18397 O\nreasons 3672 O\nto 1106 O\ndisrupt 26499 O\nthe 1103 O\ncontinuity 15126 O\nof 1104 O\ncare 1920 O\nthat 1115 O\nGB 17909 O\nprovided 2136 O\nH 145 O\n. 119 O\nR 155 O\n##J 4538 O\n##B 2064 O\nappealed 12181 O\nthe 1103 O\njustice 5299 O\n##s 1116 O\ndecision 2383 O\n. 119 O\nThat 1337 O\nappeal 5767 O\nwas 1108 O\nsuccessful 2265 O\nin 1107 O\nthe 1103 O\nHigh 1693 O\nCourt 2031 O\n, 117 O\nthe 1103 O\njudge 3942 O\nfinding 4006 O\nthat 1115 O\nthe 1103 O\njustice 5299 O\n##s 1116 O\nhad 1125 O\nbeen 1151 O\nplain 6188 O\n##ly 1193 O\nwrong 2488 O\nin 1107 O\nmaking 1543 O\nthe 1103 O\nresidence 4662 O\norder 1546 O\nin 1107 O\nfavour 7511 O\nof 1104 O\nGB 17909 O\n, 117 O\nhaving 1515 O\nbeen 1151 O\ndistracted 11353 O\nby 1118 O\nthe 1103 O\nsettled 3035 O\nway 1236 O\nin 1107 O\nwhich 1134 O\nH 145 O\nhad 1125 O\nbeen 1151 O\nbrought 1814 O\nup 1146 O\nby 1118 O\nGB 17909 O\n. 119 O\nIn 1130 O\nApril 1364 B-tim\n2009 1371 I-tim\n, 117 O\nthe 1103 O\nHigh 1693 O\nCourt 2031 O\nmade 1189 O\nan 1126 O\norder 1546 O\nthat 1115 O\nH 145 O\nshould 1431 O\nreside 14487 O\nwith 1114 O\nR 155 O\n##J 4538 O\n##B 2064 O\n. 119 O\nThe 1109 O\norder 1546 O\nof 1104 O\nthe 1103 O\nHigh 1693 O\nCourt 2031 O\nwas 1108 O\nappealed 12181 O\nby 1118 O\nGB 17909 O\nin 1107 O\nthe 1103 O\nCourt 2031 O\nof 1104 I-org\nAppeal 13969 O\n. 119 O\nThe 1109 O\nCourt 2031 O\nof 1104 I-org\nAppeal 13969 O\ndismissed 6714 O\nthe 1103 O\nappeal 5767 O\nholding 2355 O\nthat 1115 O\nin 1107 O\ngiving 2368 O\ndi 4267 O\n##sp 20080 O\n##rop 12736 O\n##ort 12148 O\n##ion 1988 O\n##ate 2193 O\nweight 2841 O\nto 1106 O\nthe 1103 O\nstatus 2781 O\nq 186 O\n##uo 11848 O\nthe 1103 O\njustice 5299 O\n##s 1116 O\nhad 1125 O\nmade 1189 O\nan 1126 O\nerror 7353 O\nof 1104 O\nlaw 1644 O\nsufficient 6664 O\nto 1106 O\nen 4035 O\n##ti 3121 O\n##tle 5034 O\nthe 1103 O\ncircuit 6090 O\njudge 3942 O\nto 1106 O\nover 1166 O\n##ru 5082 O\n##le 1513 O\ntheir 1147 O\ndecision 2383 O\n. 119 O\nA 138 O\n##pp 8661 O\n##lying 15318 O\nRe 11336 O\nG 144 O\n( 113 O\nChildren 4288 O\n) 114 O\n( 113 O\nResidence 18774 O\n: 131 O\nSame 14060 O\nSex 9850 O\nPartner 24961 O\n) 114 O\n[ 164 O\n2006 1386 O\n] 166 O\n1 122 O\nW 160 O\n##LR 26161 O\n230 11866 O\n##5 1571 O\n, 117 O\nand 1105 O\nin 1107 O\nparticular 2440 O\nthe 1103 O\nobservations 9959 O\nin 1107 O\nthat 1115 O\ncase 1692 O\nof 1104 O\nLord 2188 B-per\nNi 27453 O\n##cho 8401 O\n##lls 9872 O\n, 117 O\nthe 1103 O\nCourt 2031 O\nof 1104 O\nAppeal 13969 O\nheld 1316 O\nthat 1115 O\nalthough 1780 O\na 170 O\nchild 2027 O\n##s 1116 O\nwelfare 9319 O\nwas 1108 O\nthe 1103 O\ncourts 5333 O\npara 18311 O\n##mount 15364 O\nconsideration 9486 O\n, 117 O\nthe 1103 O\ncourt 2175 O\nshould 1431 O\nalways 1579 O\nbear 4965 O\nin 1107 O\nmind 1713 O\nthat 1115 O\n, 117 O\nor 1137 O\n##dina 18140 O\n##rily 11486 O\n, 117 O\nthe 1103 O\nrear 3876 O\n##ing 1158 O\nof 1104 O\na 170 O\nchild 2027 O\nby 1118 O\nhis 1117 O\nbiological 7269 O\nparent 6486 O\ncould 1180 O\nbe 1129 O\nexpected 2637 O\nto 1106 O\nbe 1129 O\nin 1107 O\nhis 1117 O\nbest 1436 O\ninterests 4740 O\n. 119 O\nThe 1109 O\nSupreme 3732 O\nCourt 2031 O\nunanimously 16642 O\nallowed 2148 O\nthe 1103 O\nappeal 5767 O\nby 1118 O\nGB 17909 O\n. 119 O\nIn 1130 O\ndoing 1833 O\nso 1177 O\n, 117 O\nit 1122 O\nre 1231 O\n##af 9823 O\n##firmed 22750 O\nthe 1103 O\ncentral 2129 O\nmessage 3802 O\nin 1107 O\nRe 11336 O\nG 144 O\nthat 1115 O\n, 117 O\nwhere 1187 O\nin 1107 O\na 170 O\ncase 1692 O\nbetween 1206 O\nprivate 2029 O\nindividuals 2833 O\na 170 O\nchild 2027 O\n##s 1116 O\ncustody 9948 O\nor 1137 O\nupbringing 27981 O\nis 1110 O\nin 1107 O\nquestion 2304 O\n, 117 O\nthe 1103 O\nwelfare 9319 O\nof 1104 O\nthe 1103 O\nchild 2027 O\nis 1110 O\nthe 1103 O\npara 18311 O\n##mount 15364 O\nconsideration 9486 O\n. 119 O\nThe 1109 O\njudgment 9228 O\ndelivered 4653 O\nby 1118 O\nLord 2188 O\nKerr 15587 O\nwas 1108 O\nthe 1103 O\njudgment 9228 O\nof 1104 O\nthe 1103 O\ncourt 2175 O\nto 1106 O\nwhich 1134 O\nall 1155 O\nof 1104 O\nits 1157 O\nmembers 1484 O\ncontributed 4415 O\n. 119 O\nA 138 O\nchild 2027 O\n##s 1116 O\nImportant Words:  ['July 2006', 'November 2006', 'May 2008', 'Proceedings', 'March 2009', 'April 2009', 'of', 'of', 'Lord']\n","output_type":"stream"}]}]}