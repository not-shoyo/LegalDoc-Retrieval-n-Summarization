{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6761784,"sourceType":"datasetVersion","datasetId":3891699},{"sourceId":6762107,"sourceType":"datasetVersion","datasetId":3891873}],"dockerImageVersionId":30559,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import json\njson_rr_data = json.load(open('/kaggle/input/d/hamnamuslihuddeen/rhetorical-role-dataset/RR_Train.json'))","metadata":{"execution":{"iopub.status.busy":"2023-11-16T10:36:35.013129Z","iopub.execute_input":"2023-11-16T10:36:35.013479Z","iopub.status.idle":"2023-11-16T10:36:35.532978Z","shell.execute_reply.started":"2023-11-16T10:36:35.013449Z","shell.execute_reply":"2023-11-16T10:36:35.531622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# json_rr_data[0]","metadata":{"execution":{"iopub.status.busy":"2023-11-16T07:21:34.847742Z","iopub.execute_input":"2023-11-16T07:21:34.848076Z","iopub.status.idle":"2023-11-16T07:21:34.852071Z","shell.execute_reply.started":"2023-11-16T07:21:34.848047Z","shell.execute_reply":"2023-11-16T07:21:34.851127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(json_rr_data)","metadata":{"execution":{"iopub.status.busy":"2023-11-16T10:36:39.493263Z","iopub.execute_input":"2023-11-16T10:36:39.493767Z","iopub.status.idle":"2023-11-16T10:36:39.501751Z","shell.execute_reply.started":"2023-11-16T10:36:39.493724Z","shell.execute_reply":"2023-11-16T10:36:39.500450Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(json_rr_data[225])","metadata":{"execution":{"iopub.status.busy":"2023-11-16T10:38:18.654863Z","iopub.execute_input":"2023-11-16T10:38:18.655260Z","iopub.status.idle":"2023-11-16T10:38:18.661355Z","shell.execute_reply.started":"2023-11-16T10:38:18.655229Z","shell.execute_reply":"2023-11-16T10:38:18.660435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we have loaded a labelled dataset called RR_Train.json of 247 cases. With information about a case's type (criminal etc), the case doc text, the segments in the document and their respective labels.","metadata":{}},{"cell_type":"code","source":"embedding_file_creation_directory = '/kaggle/working/'","metadata":{"execution":{"iopub.status.busy":"2023-11-16T07:21:34.863361Z","iopub.execute_input":"2023-11-16T07:21:34.863639Z","iopub.status.idle":"2023-11-16T07:21:34.870971Z","shell.execute_reply.started":"2023-11-16T07:21:34.863618Z","shell.execute_reply":"2023-11-16T07:21:34.870078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install transformers\n!pip install sentence-transformers","metadata":{"execution":{"iopub.status.busy":"2023-11-16T07:21:34.872597Z","iopub.execute_input":"2023-11-16T07:21:34.872844Z","iopub.status.idle":"2023-11-16T07:21:57.905450Z","shell.execute_reply.started":"2023-11-16T07:21:34.872822Z","shell.execute_reply":"2023-11-16T07:21:57.903918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\nimport numpy as np\nimport torch\nfrom transformers import AutoModel, AutoTokenizer\nfrom sentence_transformers import SentenceTransformer, models\n\n# Define the path to the LegalBERT model and tokenizer\nmodel_name = \"nlpaueb/legal-bert-small-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nlegal_bert_model = AutoModel.from_pretrained(model_name)\n\n# Define a SentenceTransformer model with LegalBERT\nword_embedding_model = models.Transformer(model_name)\npooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\nlegal_bert_model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n\n\n\ndef s_bert(flag):\n    # Encode the input text using LegalBERT\n    embeddings = legal_bert_model.encode(flag, convert_to_tensor=True)\n    return [float(x) for x in embeddings[0].tolist()]\n\ncount=0\n\nfor i in range(247):\n    print(i)\n    filename = embedding_file_creation_directory + \"c\"+str(count)+\".txt\"    \n    if len(json_rr_data[i]['annotations'][0]['result'])==0:\n        continue\n    count+=1\n    with open(filename, \"w\") as file1:\n        for j in json_rr_data[i]['annotations'][0]['result']:\n            temp = j['value']['text'].replace(\"\\n\", \" \")\n            temp = ' '.join(temp.split())  # Remove extra spaces\n\n            flag = [temp]\n            emb = s_bert(flag)\n            vec_emb = \" \".join(str(float('{:.5f}'.format(n))) for n in emb)\n            label = j['value']['labels'][0]\n            if count==0:\n                file1.write(f\"{vec_emb}\\t{label}\")\n            else:\n                file1.write(f\"\\n{vec_emb}\\t{label}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-11-16T07:21:57.909441Z","iopub.execute_input":"2023-11-16T07:21:57.909793Z","iopub.status.idle":"2023-11-16T07:45:35.971370Z","shell.execute_reply.started":"2023-11-16T07:21:57.909762Z","shell.execute_reply":"2023-11-16T07:45:35.970614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"After reviewing the generated c0.txt, we can see that each row has 768 embeddings followed with the Rhetorical Role.\nc0.txt contains the embedding for each part of the first document. All of the embeddings for each part used to be same btu after initializing vectorizer before every part, the embeddings have changed.","metadata":{}}]}