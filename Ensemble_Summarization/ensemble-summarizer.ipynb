{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-08T12:11:11.241620Z","iopub.status.busy":"2023-12-08T12:11:11.240836Z","iopub.status.idle":"2023-12-08T12:11:11.253784Z","shell.execute_reply":"2023-12-08T12:11:11.252788Z","shell.execute_reply.started":"2023-12-08T12:11:11.241578Z"},"trusted":true},"outputs":[],"source":["#defining file path for test dataset\n","dataset = \"IN-Abs\" # Options: IN - IN-Abs, UK-UK-Abs, N2-IN-Ext\n","output_path = \"/kaggle/working/output/\""]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-08T12:11:15.359439Z","iopub.status.busy":"2023-12-08T12:11:15.358577Z","iopub.status.idle":"2023-12-08T12:11:15.366486Z","shell.execute_reply":"2023-12-08T12:11:15.365508Z","shell.execute_reply.started":"2023-12-08T12:11:15.359405Z"},"trusted":true},"outputs":[],"source":["cd /kaggle/input/utilis"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-08T12:11:17.624881Z","iopub.status.busy":"2023-12-08T12:11:17.624543Z","iopub.status.idle":"2023-12-08T12:11:23.302107Z","shell.execute_reply":"2023-12-08T12:11:23.301127Z","shell.execute_reply.started":"2023-12-08T12:11:17.624853Z"},"trusted":true},"outputs":[],"source":["#importing necessary libraries\n","import pandas as pd\n","import numpy as np\n","import glob\n","import sys\n","sys.path.insert(0, '../')\n","from utilities import *\n","import os\n","import nltk"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-08T12:11:29.263834Z","iopub.status.busy":"2023-12-08T12:11:29.263333Z","iopub.status.idle":"2023-12-08T12:11:29.268905Z","shell.execute_reply":"2023-12-08T12:11:29.267920Z","shell.execute_reply.started":"2023-12-08T12:11:29.263806Z"},"trusted":true},"outputs":[],"source":["#creating output directory if it doesnt exist\n","if not os.path.exists(output_path):\n","    os.makedirs(output_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-08T12:11:32.279695Z","iopub.status.busy":"2023-12-08T12:11:32.278862Z","iopub.status.idle":"2023-12-08T12:11:32.736821Z","shell.execute_reply":"2023-12-08T12:11:32.735621Z","shell.execute_reply.started":"2023-12-08T12:11:32.279661Z"},"trusted":true},"outputs":[],"source":["names, data_source, data_summary = get_summary_data(dataset, \"test\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-08T12:11:35.290121Z","iopub.status.busy":"2023-12-08T12:11:35.289519Z","iopub.status.idle":"2023-12-08T12:11:35.297267Z","shell.execute_reply":"2023-12-08T12:11:35.295906Z","shell.execute_reply.started":"2023-12-08T12:11:35.290079Z"},"trusted":true},"outputs":[],"source":["cd /kaggle/input/"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-08T12:11:38.718491Z","iopub.status.busy":"2023-12-08T12:11:38.718125Z","iopub.status.idle":"2023-12-08T12:11:38.723326Z","shell.execute_reply":"2023-12-08T12:11:38.722257Z","shell.execute_reply.started":"2023-12-08T12:11:38.718462Z"},"trusted":true},"outputs":[],"source":["#references is a list containg all the summaries in the test dataset\n","references=list()\n","for reference_summary in data_summary:\n","    references.append(reference_summary)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-08T12:13:15.526685Z","iopub.status.busy":"2023-12-08T12:13:15.525970Z","iopub.status.idle":"2023-12-08T12:13:15.537104Z","shell.execute_reply":"2023-12-08T12:13:15.536121Z","shell.execute_reply.started":"2023-12-08T12:13:15.526651Z"},"trusted":true},"outputs":[],"source":["summarylength=list()\n","docid=list()\n","for i in references:\n","    summarylength.append(len(i.split(\" \")))\n","for i in range(1,len(summarylength)+1):\n","    docid.append(i)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-19T19:48:00.857739Z","iopub.status.busy":"2023-11-19T19:48:00.857442Z","iopub.status.idle":"2023-11-19T19:48:00.862382Z","shell.execute_reply":"2023-11-19T19:48:00.861477Z","shell.execute_reply.started":"2023-11-19T19:48:00.857715Z"},"trusted":true},"outputs":[],"source":["# print(summarylength)\n","# print(docid)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-08T12:13:20.756957Z","iopub.status.busy":"2023-12-08T12:13:20.756114Z","iopub.status.idle":"2023-12-08T12:13:21.249036Z","shell.execute_reply":"2023-12-08T12:13:21.248082Z","shell.execute_reply.started":"2023-12-08T12:13:20.756923Z"},"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","avg_summary_length = np.mean(summarylength)\n","\n","# Plotting\n","plt.figure(figsize=(6, 4))  # Adjust figure size if needed\n","plt.bar(docid, summarylength, color='skyblue', label='Summary Length')\n","plt.axhline(y=avg_summary_length, color='red', linestyle='--', label=f'Average: {avg_summary_length:.2f}')\n","plt.xlabel('Document ID')\n","plt.ylabel('Summary Length')\n","plt.ylim(0, 8000)\n","plt.title('Summary Lengths for Different Documents')\n","plt.xticks(rotation=45)  # Rotate x-axis labels for better visibility\n","plt.legend()\n","plt.tight_layout()\n","\n","# Show plot\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-08T12:13:25.585209Z","iopub.status.busy":"2023-12-08T12:13:25.584809Z","iopub.status.idle":"2023-12-08T12:13:25.603574Z","shell.execute_reply":"2023-12-08T12:13:25.602558Z","shell.execute_reply.started":"2023-12-08T12:13:25.585175Z"},"trusted":true},"outputs":[],"source":["total_length = sum(len(string.split(\" \")) for string in references)\n","l=len(references[0].split(\" \"))\n","for i in references:\n","    l=max(l,len(i.split(\" \")))\n","print(l)\n","print(references[0])\n","# Calculate average length\n","average_length = total_length / len(references)\n","print(average_length)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-08T12:13:31.826649Z","iopub.status.busy":"2023-12-08T12:13:31.825776Z","iopub.status.idle":"2023-12-08T12:13:31.832695Z","shell.execute_reply":"2023-12-08T12:13:31.831779Z","shell.execute_reply.started":"2023-12-08T12:13:31.826617Z"},"trusted":true},"outputs":[],"source":["cd /kaggle/input/bart-utilities"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-08T12:13:34.294951Z","iopub.status.busy":"2023-12-08T12:13:34.294055Z","iopub.status.idle":"2023-12-08T12:15:01.282919Z","shell.execute_reply":"2023-12-08T12:15:01.281923Z","shell.execute_reply.started":"2023-12-08T12:13:34.294916Z"},"trusted":true},"outputs":[],"source":["import torch\n","from transformers import PegasusForConditionalGeneration, PegasusTokenizer, BartForConditionalGeneration, BartTokenizer\n","from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n","from transformers import BartTokenizer, BartForConditionalGeneration, AdamW, BartConfig\n","from BART_utilities import *\n","#loading gpu\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Load the fine-tuned pegasus model\n","pegasus_tokenizer = AutoTokenizer.from_pretrained(\"nsi319/legal-pegasus\") \n","pegasus_model = AutoModelForSeq2SeqLM.from_pretrained(\"/kaggle/input/output-model\")\n","pegasus_model.to(device)\n","\n","\n","# Loading Bart Model and tokenizer\n","\n","\n","\n","base_bart_model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large\")\n","base_bart_model.to(device)\n","\n","bart_tokenizer = BartTokenizer.from_pretrained('facebook/bart-large', add_prefix_space=True)\n","new_tokens = ['<F>', '<RLC>', '<A>', '<S>', '<P>', '<R>', '<RPC>']\n","special_tokens_dict = {'additional_special_tokens': new_tokens}\n","num_added_toks = bart_tokenizer.add_special_tokens(special_tokens_dict)\n","base_bart_model.resize_token_embeddings(len(bart_tokenizer))\n","print(len(bart_tokenizer))\n","\n","# Load the fine-tuned bart model\n","bart_model = LitModel(learning_rate = 2e-5, tokenizer = bart_tokenizer, model = base_bart_model)\n","bart_model.load_state_dict(torch.load(\"/kaggle/input/bartmodel/outputBARTModel (1).pt\"))\n","bart_model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-08T12:15:01.284981Z","iopub.status.busy":"2023-12-08T12:15:01.284541Z","iopub.status.idle":"2023-12-08T12:15:01.290415Z","shell.execute_reply":"2023-12-08T12:15:01.289406Z","shell.execute_reply.started":"2023-12-08T12:15:01.284954Z"},"trusted":true},"outputs":[],"source":["from difflib import SequenceMatcher\n","\n","def similarity_score(text1, text2):\n","    return SequenceMatcher(None, text1, text2).ratio()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-08T12:37:57.777043Z","iopub.status.busy":"2023-12-08T12:37:57.776330Z","iopub.status.idle":"2023-12-08T12:37:57.782440Z","shell.execute_reply":"2023-12-08T12:37:57.781468Z","shell.execute_reply.started":"2023-12-08T12:37:57.777008Z"},"trusted":true},"outputs":[],"source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","def cosine_similarity_score(text1, text2):\n","    vectorizer = TfidfVectorizer()\n","    vectors = vectorizer.fit_transform([text1, text2])\n","    similarity = cosine_similarity(vectors[0], vectors[1])[0][0]\n","    return similarity"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-08T13:49:32.102926Z","iopub.status.busy":"2023-12-08T13:49:32.101975Z","iopub.status.idle":"2023-12-08T13:49:32.113259Z","shell.execute_reply":"2023-12-08T13:49:32.112220Z","shell.execute_reply.started":"2023-12-08T13:49:32.102889Z"},"trusted":true},"outputs":[],"source":["def ensemble_summarizer(text):\n","# Generate summary using Legal PEGASUS\n","    pegasus_input_tokenized = pegasus_tokenizer.encode(text, return_tensors='pt', max_length=1024, truncation=True)\n","    pegasus_input_tokenized = pegasus_input_tokenized.to(device)  # Move input tensor to GPU if available\n","    # Ensure the model and input tensors are on the same device\n","    with torch.no_grad():\n","        pegasus_summary_ids = pegasus_model.generate(pegasus_input_tokenized,\n","                                                num_beams=9,\n","                                                no_repeat_ngram_size=3,\n","                                                length_penalty=2.0,\n","                                                min_length=200,\n","                                                max_length=1000,\n","                                                early_stopping=True)\n","    pegasus_summary = [pegasus_tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in pegasus_summary_ids][0]\n","   \n","\n","    \n","    # Generate summary using BART\n","    \n","    bart_input_tokenized = bart_tokenizer.encode(text, truncation=True, return_tensors='pt')\n","    bart_input_tokenized = bart_input_tokenized.to(device)\n","    bart_summary_ids = bart_model.model.to(device).generate(bart_input_tokenized,\n","                                  length_penalty=0.01,\n","                                  min_length=200,\n","                                  max_length=1000)\n","    bart_summary = [bart_tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in bart_summary_ids][0]\n","\n","  \n","    \n","    \n","    bart_legal_similarity = cosine_similarity_score(bart_summary, pegasus_summary)\n","\n","    # Select the summary with higher similarity or a specific threshold\n","    if bart_legal_similarity >=0.9:  # Adjust the threshold as needed\n","        ensemble_summary = bart_summary  # Select BERT summary\n","    else:\n","        # If the similarity is low, choose the longer summary as the ensemble result\n","        if len(bart_summary) >= len(pegasus_summary):\n","            ensemble_summary = bart_summary\n","        else:\n","            ensemble_summary =pegasus_summary\n","    \n","    return ensemble_summary\n","    \n","    \n","\n"]},{"cell_type":"markdown","metadata":{},"source":["Evaluating the model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-08T12:16:22.197998Z","iopub.status.busy":"2023-12-08T12:16:22.197055Z","iopub.status.idle":"2023-12-08T12:16:49.512907Z","shell.execute_reply":"2023-12-08T12:16:49.511706Z","shell.execute_reply.started":"2023-12-08T12:16:22.197963Z"},"trusted":true},"outputs":[],"source":["!pip install evaluate\n","!pip install rouge_score"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-08T14:02:49.829393Z","iopub.status.busy":"2023-12-08T14:02:49.828994Z","iopub.status.idle":"2023-12-08T14:08:35.625119Z","shell.execute_reply":"2023-12-08T14:08:35.624207Z","shell.execute_reply.started":"2023-12-08T14:02:49.829361Z"},"trusted":true},"outputs":[],"source":["from evaluate import load\n","# Load the ROUGE metric\n","import evaluate\n","\n","candidates=list()\n","for text in data_source[:5]:\n","    candidates.append(ensemble_summarizer(text))\n","\n","rouge = evaluate.load('rouge')\n","\n","results = rouge.compute(predictions=candidates, references=references[:5])\n","\n","print(results)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-08T12:29:19.935384Z","iopub.status.busy":"2023-12-08T12:29:19.934591Z","iopub.status.idle":"2023-12-08T12:29:19.946577Z","shell.execute_reply":"2023-12-08T12:29:19.945431Z","shell.execute_reply.started":"2023-12-08T12:29:19.935350Z"},"trusted":true},"outputs":[],"source":["# a new function that takes in the list of rhetorical roles and the judgements, removes each rhetorical role one by one and generates the summary using ensemble summarizer. and stores that summary.\n","# so we will need 13 lists each list consisting of the summaries of all the judgements formed after removing that one rhetorical role.\n","rogueResults=dict()\n","\n","def removeRhetoricalRole(role,data_source):\n","    #A function that takes in the rhetorical role and the text and removes the rhetorical role of the text and returns the new text\n","    removed_role_data_source=list()\n","\n","    for text in data_source:\n","        #for loop passing through each text in  datasource and removing the rr and append that to a list removed_role_data_source.\n","        updated_text=text #code to remove rr\n","        removed_role_data_source.append(updated_text)\n","\n","    return removed_role_data_source\n","\n","\n","roles = ['PREAMBLE','NONE','FAC','ISSUE','ARG_PETITIONER','RLC','ANALYSIS','PRE_RELIED','RATIO','RPC','STA','ARG_RESPONDENT','PRE_NOT_RELIED']\n","\n","def rhetoricalRole_Analysis(roles, data_source):\n","\n","    for role in roles:\n","        removed_rr_summaries=list()\n","        removed_RR_data_source= removeRhetoricalRole(role,data_source)\n","\n","        for text in removed_RR_data_source[:1]:\n","            removed_rr_summaries.append(ensemble_summarizer(text))\n","            \n","        rouge = evaluate.load('rouge')\n","\n","        results_references = rouge.compute(predictions=removed_rr_summaries, references=references[:1])\n","        results_generated = rouge.compute(predictions=removed_rr_summaries, references=candidates[:1])\n","        \n","        rogueResults[role]=dict()\n","        rogueResults[role][\"Reference\"]=results_references\n","        rogueResults[role][\"Generated\"]=results_generated\n","\n","        \n","    \n","    \n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-08T12:29:29.444953Z","iopub.status.busy":"2023-12-08T12:29:29.444572Z","iopub.status.idle":"2023-12-08T12:33:28.880601Z","shell.execute_reply":"2023-12-08T12:33:28.879616Z","shell.execute_reply.started":"2023-12-08T12:29:29.444926Z"},"trusted":true},"outputs":[],"source":["rhetoricalRole_Analysis(roles, data_source)\n","print(rogueResults)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-19T19:55:15.207351Z","iopub.status.busy":"2023-11-19T19:55:15.206653Z","iopub.status.idle":"2023-11-19T19:55:43.597945Z","shell.execute_reply":"2023-11-19T19:55:43.596959Z","shell.execute_reply.started":"2023-11-19T19:55:15.207309Z"},"trusted":true},"outputs":[],"source":["from nltk.translate.bleu_score import corpus_bleu\n","\n","\n","\n","# Calculate BLEU scores\n","bleu = corpus_bleu(references[:5], candidates)\n","\n","print(f'Ensemble BLEU Score: {bleu:.4f}')\n"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":3963711,"sourceId":6900273,"sourceType":"datasetVersion"},{"datasetId":3963755,"sourceId":6900361,"sourceType":"datasetVersion"},{"datasetId":3972919,"sourceId":6919028,"sourceType":"datasetVersion"},{"datasetId":4013140,"sourceId":6982894,"sourceType":"datasetVersion"},{"datasetId":4020740,"sourceId":6995040,"sourceType":"datasetVersion"},{"datasetId":4022620,"sourceId":6997719,"sourceType":"datasetVersion"}],"dockerImageVersionId":30588,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
