{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d766709",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-03-25T21:47:15.157075Z",
     "iopub.status.busy": "2024-03-25T21:47:15.156718Z",
     "iopub.status.idle": "2024-03-25T21:47:31.636727Z",
     "shell.execute_reply": "2024-03-25T21:47:31.634623Z"
    },
    "papermill": {
     "duration": 16.487453,
     "end_time": "2024-03-25T21:47:31.639266",
     "exception": false,
     "start_time": "2024-03-25T21:47:15.151813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\r\n",
      "  Downloading openai-1.14.3-py3-none-any.whl.metadata (20 kB)\r\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from openai) (4.2.0)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai) (1.9.0)\r\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from openai) (0.27.0)\r\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from openai) (2.5.3)\r\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai) (1.3.0)\r\n",
      "Requirement already satisfied: tqdm>4 in /opt/conda/lib/python3.10/site-packages (from openai) (4.66.1)\r\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/lib/python3.10/site-packages (from openai) (4.9.0)\r\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.6)\r\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\r\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\r\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.4)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.14.6)\r\n",
      "Downloading openai-1.14.3-py3-none-any.whl (262 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m262.9/262.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: openai\r\n",
      "Successfully installed openai-1.14.3\r\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d629a911",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-25T21:47:31.649041Z",
     "iopub.status.busy": "2024-03-25T21:47:31.648593Z",
     "iopub.status.idle": "2024-03-25T21:48:19.407166Z",
     "shell.execute_reply": "2024-03-25T21:48:19.405279Z"
    },
    "papermill": {
     "duration": 47.766896,
     "end_time": "2024-03-25T21:48:19.409751",
     "exception": false,
     "start_time": "2024-03-25T21:47:31.642855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\r\n",
      "  Downloading langchain-0.1.13-py3-none-any.whl.metadata (13 kB)\r\n",
      "Collecting neo4j\r\n",
      "  Downloading neo4j-5.18.0.tar.gz (198 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.0/198.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \bdone\r\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: openai in /opt/conda/lib/python3.10/site-packages (1.14.3)\r\n",
      "Collecting wikipedia\r\n",
      "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hCollecting tiktoken\r\n",
      "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\r\n",
      "Collecting langchain_openai\r\n",
      "  Downloading langchain_openai-0.1.1-py3-none-any.whl.metadata (2.5 kB)\r\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0.1)\r\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.25)\r\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.9.1)\r\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\r\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.6.4)\r\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.33)\r\n",
      "Collecting langchain-community<0.1,>=0.0.29 (from langchain)\r\n",
      "  Downloading langchain_community-0.0.29-py3-none-any.whl.metadata (8.3 kB)\r\n",
      "Collecting langchain-core<0.2.0,>=0.1.33 (from langchain)\r\n",
      "  Downloading langchain_core-0.1.33-py3-none-any.whl.metadata (6.0 kB)\r\n",
      "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\r\n",
      "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl.metadata (2.0 kB)\r\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\r\n",
      "  Downloading langsmith-0.1.31-py3-none-any.whl.metadata (13 kB)\r\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.26.4)\r\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.5.3)\r\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.31.0)\r\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.2.3)\r\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.10/site-packages (from neo4j) (2023.3.post1)\r\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from openai) (4.2.0)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai) (1.9.0)\r\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from openai) (0.27.0)\r\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai) (1.3.0)\r\n",
      "Requirement already satisfied: tqdm>4 in /opt/conda/lib/python3.10/site-packages (from openai) (4.66.1)\r\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/lib/python3.10/site-packages (from openai) (4.9.0)\r\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from wikipedia) (4.12.2)\r\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken) (2023.12.25)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\r\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.6)\r\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\r\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\r\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\r\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\r\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.4)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\r\n",
      "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.33->langchain)\r\n",
      "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\r\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\r\n",
      "  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.14.6)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.18)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->wikipedia) (2.5)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\r\n",
      "Downloading langchain-0.1.13-py3-none-any.whl (810 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m810.5/810.5 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading langchain_openai-0.1.1-py3-none-any.whl (32 kB)\r\n",
      "Downloading langchain_community-0.0.29-py3-none-any.whl (1.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading langchain_core-0.1.33-py3-none-any.whl (269 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.1/269.1 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\r\n",
      "Downloading langsmith-0.1.31-py3-none-any.whl (71 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading packaging-23.2-py3-none-any.whl (53 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hBuilding wheels for collected packages: neo4j, wikipedia\r\n",
      "  Building wheel for neo4j (pyproject.toml) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for neo4j: filename=neo4j-5.18.0-py3-none-any.whl size=273863 sha256=32f47d579e42b0de3af8ad051563966393537d9ae5719feff414fdfb5ff9edc1\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/e7/e1/a0/dd7c19192f5383ff57d02a6c126cbfe4b7b2ae82f70c6994ce\r\n",
      "  Building wheel for wikipedia (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11678 sha256=15f431c813e15c7fd93de80359341a65458a6a4a522773f4c3fa6219a0d658ea\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/5e/b6/c5/93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\r\n",
      "Successfully built neo4j wikipedia\r\n",
      "Installing collected packages: packaging, orjson, neo4j, wikipedia, tiktoken, langsmith, langchain-core, langchain-text-splitters, langchain_openai, langchain-community, langchain\r\n",
      "  Attempting uninstall: packaging\r\n",
      "    Found existing installation: packaging 21.3\r\n",
      "    Uninstalling packaging-21.3:\r\n",
      "      Successfully uninstalled packaging-21.3\r\n",
      "  Attempting uninstall: orjson\r\n",
      "    Found existing installation: orjson 3.9.10\r\n",
      "    Uninstalling orjson-3.9.10:\r\n",
      "      Successfully uninstalled orjson-3.9.10\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "keras-cv 0.8.2 requires keras-core, which is not installed.\r\n",
      "keras-nlp 0.8.2 requires keras-core, which is not installed.\r\n",
      "tensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\r\n",
      "apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 15.0.2 which is incompatible.\r\n",
      "google-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 23.2 which is incompatible.\r\n",
      "jupyterlab 4.1.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "jupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "momepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "osmnx 1.9.1 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "spopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.0.5 which is incompatible.\r\n",
      "ydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed langchain-0.1.13 langchain-community-0.0.29 langchain-core-0.1.33 langchain-text-splitters-0.0.1 langchain_openai-0.1.1 langsmith-0.1.31 neo4j-5.18.0 orjson-3.9.15 packaging-23.2 tiktoken-0.6.0 wikipedia-1.4.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain neo4j openai wikipedia tiktoken langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "623b08bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-25T21:48:19.426507Z",
     "iopub.status.busy": "2024-03-25T21:48:19.426175Z",
     "iopub.status.idle": "2024-03-25T21:48:21.353831Z",
     "shell.execute_reply": "2024-03-25T21:48:21.352444Z"
    },
    "papermill": {
     "duration": 1.939682,
     "end_time": "2024-03-25T21:48:21.356783",
     "exception": false,
     "start_time": "2024-03-25T21:48:19.417101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chains.openai_functions import create_structured_output_chain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from typing import List, Optional\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "def get_extraction_chain(\n",
    "    document: Optional[List[str]] = None,\n",
    "    rhetorical_role: Optional[List[str]] = None,\n",
    "    weights: Optional[List[float]] = None):\n",
    "    \n",
    "    # Construct the prompt\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", f\"\"\"# Document Summary Generation Instructions\n",
    "\n",
    "{\"## Document to Be Summarized: \" + \", \".join(document) if document else \"\"}\n",
    "\n",
    "\n",
    "{\"## Rhetorical Role Labels for Each Sentence: \" + \", \".join(rhetorical_role) if rhetorical_role else \"\"}\n",
    "\n",
    "{\"## Importance Weights for Each Rhetorical Role: \" + \", \".join(str(weights)) if weights else \"\"}\n",
    "- The weight of Rhetorical Role 'x' will be at position 'x-3' in the weights list.\n",
    "\n",
    "## 1. Overview\n",
    "This document requires summarization based on its content and the assigned rhetorical roles for each sentence.\n",
    "\n",
    "## 2. Document Analysis\n",
    "- **Document Content**: The provided document contains information that needs to be condensed into a summary.\n",
    "- **Rhetorical Role Labels**: Each sentence in the document is labeled with a specific rhetorical role to denote its significance. \n",
    "\n",
    "## 3. Rhetorical Role Weights\n",
    "- **Rhetorical Role Importance**: The importance of each rhetorical role is represented by the assigned weights. Higher weights indicate greater importance. Higher weights also indicate higher probability of being included in the summary.\n",
    "\n",
    "## 4. Summary Generation Process\n",
    "The summary generation process will utilize advanced language models to distill the key information from the document, taking into account the rhetorical roles and their respective weights.\n",
    "\n",
    "## 5. Output\n",
    "The generated summary will provide a concise overview of the document's content, emphasizing the most important information based on the assigned rhetorical roles and their weights.\n",
    "\n",
    "## 6. Additional Notes\n",
    "Please review the generated summary to ensure it accurately captures the essential details of the document. Summary should be around 500 words.\"\"\")\n",
    "    ])\n",
    "\n",
    "    # Return the prompt\n",
    "    return prompt.invoke({\n",
    "        \"document\": document,\n",
    "        \"rhetorical_roles\": rhetorical_roles,\n",
    "        \"weights\": weights\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d4106ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-25T21:48:21.377356Z",
     "iopub.status.busy": "2024-03-25T21:48:21.376826Z",
     "iopub.status.idle": "2024-03-25T21:48:23.686476Z",
     "shell.execute_reply": "2024-03-25T21:48:23.685062Z"
    },
    "papermill": {
     "duration": 2.324183,
     "end_time": "2024-03-25T21:48:23.689451",
     "exception": false,
     "start_time": "2024-03-25T21:48:21.365268",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>pred</th>\n",
       "      <th>emb</th>\n",
       "      <th>doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>[4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[[0.27125, 0.43958, -0.40032, -0.59358, 1.0063...</td>\n",
       "      <td>['(Civil) No. 548 of 1987.', '(Under Article 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>[3, 3, 4, 4, 4, 4, 8, 8, 8, 8, 8, 5, 4, 5, 5, ...</td>\n",
       "      <td>[[-0.99177, 0.18211, -0.47092, 0.25772, 0.4945...</td>\n",
       "      <td>['N: Criminal Appeal Nos.', '287 &amp; 288 of 1980...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63</td>\n",
       "      <td>[4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[[-0.49523, 0.00739, -0.61337, -0.23871, 0.733...</td>\n",
       "      <td>[': Criminal Appeal No 133 of 1975.', 'Appeal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>82</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 4, ...</td>\n",
       "      <td>[[0.14106, 0.0147, -0.92286, -0.40899, 0.63139...</td>\n",
       "      <td>['Appeal No. 1951 of 1975.', 'Appeal by Specia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>[3, 4, 4, 4, 4, 8, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[[-0.03027, 0.1304, -0.67327, -0.23739, 0.4874...</td>\n",
       "      <td>['Civil Appeal No. 598 of 1980.', 'Appeal by S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    i                                               pred  \\\n",
       "0  11  [4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "1  13  [3, 3, 4, 4, 4, 4, 8, 8, 8, 8, 8, 5, 4, 5, 5, ...   \n",
       "2  63  [4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "3  82  [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 4, ...   \n",
       "4  18  [3, 4, 4, 4, 4, 8, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "\n",
       "                                                 emb  \\\n",
       "0  [[0.27125, 0.43958, -0.40032, -0.59358, 1.0063...   \n",
       "1  [[-0.99177, 0.18211, -0.47092, 0.25772, 0.4945...   \n",
       "2  [[-0.49523, 0.00739, -0.61337, -0.23871, 0.733...   \n",
       "3  [[0.14106, 0.0147, -0.92286, -0.40899, 0.63139...   \n",
       "4  [[-0.03027, 0.1304, -0.67327, -0.23739, 0.4874...   \n",
       "\n",
       "                                                 doc  \n",
       "0  ['(Civil) No. 548 of 1987.', '(Under Article 3...  \n",
       "1  ['N: Criminal Appeal Nos.', '287 & 288 of 1980...  \n",
       "2  [': Criminal Appeal No 133 of 1975.', 'Appeal ...  \n",
       "3  ['Appeal No. 1951 of 1975.', 'Appeal by Specia...  \n",
       "4  ['Civil Appeal No. 598 of 1980.', 'Appeal by S...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "labeled_docs_df = pd.read_csv(\"/kaggle/input/summary-dataset-rr-labelled-documents/labeled_docs.csv\")\n",
    "\n",
    "labeled_docs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78292288",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-25T21:48:23.708365Z",
     "iopub.status.busy": "2024-03-25T21:48:23.707983Z",
     "iopub.status.idle": "2024-03-25T21:48:23.723271Z",
     "shell.execute_reply": "2024-03-25T21:48:23.721537Z"
    },
    "papermill": {
     "duration": 0.026783,
     "end_time": "2024-03-25T21:48:23.725731",
     "exception": false,
     "start_time": "2024-03-25T21:48:23.698948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 8, 8, 8, 8, 8, 8, 5, 5, 13, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 11, 12, 4, 4]\n"
     ]
    }
   ],
   "source": [
    "rr = labeled_docs_df[labeled_docs_df['i']==0]['pred']\n",
    "print(rr.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0fe3d2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-25T21:48:23.742564Z",
     "iopub.status.busy": "2024-03-25T21:48:23.742213Z",
     "iopub.status.idle": "2024-03-25T21:51:43.089097Z",
     "shell.execute_reply": "2024-03-25T21:51:43.087382Z"
    },
    "papermill": {
     "duration": 199.358192,
     "end_time": "2024-03-25T21:51:43.091561",
     "exception": false,
     "start_time": "2024-03-25T21:48:23.733369",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    \n",
    "    filename = \"/kaggle/input/paper-data/documents/c\" + str(i+1) + \".txt\"\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        document = file.read()\n",
    "    document_sentences = document.split(\"\\n\")\n",
    "    \n",
    "    rhetorical_roles = labeled_docs_df[labeled_docs_df['i']==i]['pred'].iloc[0]\n",
    "    \n",
    "    weights = [\n",
    "    0.06948065923583312,\n",
    "    0.07559042913823745,\n",
    "    0.1021894882999143,\n",
    "    0.04428923435798666,\n",
    "    0.05893581574457158,\n",
    "    0.0685150718008352,\n",
    "    0.09921891683431615,\n",
    "    0.06253682699832702,\n",
    "    0.07131302632720108,\n",
    "    0.07617019334493368,\n",
    "    0.06441634179920945,\n",
    "    0.05187489618306756,\n",
    "    0.04238020893598167\n",
    "]\n",
    "    \n",
    "    prompt = get_extraction_chain(document_sentences, rhetorical_roles, weights)\n",
    "    response = llm.invoke(prompt)\n",
    "    \n",
    "    output_file = \"/kaggle/working/c\" + str(i+1) + \".txt\"\n",
    "    with open(output_file, 'w') as file:\n",
    "        file.write(response.content)\n",
    "    \n",
    "#     print(response.content)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befd9b61",
   "metadata": {
    "papermill": {
     "duration": 0.007294,
     "end_time": "2024-03-25T21:51:43.108272",
     "exception": false,
     "start_time": "2024-03-25T21:51:43.100978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0530eed9",
   "metadata": {
    "papermill": {
     "duration": 0.008491,
     "end_time": "2024-03-25T21:51:43.124318",
     "exception": false,
     "start_time": "2024-03-25T21:51:43.115827",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4137803,
     "sourceId": 7163407,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4138040,
     "sourceId": 7175201,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30673,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 272.324321,
   "end_time": "2024-03-25T21:51:44.054706",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-25T21:47:11.730385",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
